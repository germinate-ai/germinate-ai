{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Germinate AI","text":"<p>An experimental framework for building distributed LLM-based multi-agent systems (LLM-MAS). (Using NATS.io)</p> <p>One tiny step towards a billion agents running a trillion tasks on the cloud, on the edge, on your premises, and on all sorts of IOT devices.</p> <p>Important: Germinate AI is in the conception, trial and error + initial development stage. A lot of basic features mentioned in the docs aren't implemented yet, or the partial implementations don't actually work!</p>"},{"location":"#why-use-germinate","title":"Why use Germinate?","text":"<p>Germinate AI lets you define your LLM based systems as a state machine where each state is a tasks DAG. We think that this combination should be flexible and expressive enough to implement a variety of interesting LLM-MAS.</p> <p>It takes care of scheduling/parallelizing, and storing states/histories during execution.</p> <p>We use NATS as a message bus enabling ad hoc communication patterns between agents in this distributed swarm of LLM based multi-agents.</p>"},{"location":"#how-to-get-started","title":"How to get started?","text":"<ol> <li>Read this page</li> <li>Read the Quickstart</li> <li>Read the MetaGPT-ish (WIP) workflow in <code>germinate_ai/workflows/metagpt</code></li> <li>Skim the reference</li> </ol>"},{"location":"#state-machines-dag-specification-via-an-internal-dsl","title":"State Machines + DAG specification via an internal DSL","text":"<ol> <li> <p>Define a workflow which is a State machine <pre><code>workflow = Workflow(name=\"create-new-open-source-project\")\n</code></pre></p> </li> <li> <p>Define states and their tasks DAG using an internal DSL for specifying DAGs </p> <pre><code>ideate = State(name=\"ideate\")\n\n@ideate.task(namespace=\"agents.ideate\")\ndef brainstorm(...):\n    ...\n\n@ideate.task(namespace=\"tools.search_github\")\ndef search_github_for_similar_projects(...):\n    ...\n\n@ideate.task(namespace=\"agents.ideate\")\ndef write_pros_and_cons(...):\n    ...\n\n@ideate.task(namespace=\"agents.ideate\")\ndef shortlist_ideas(...):\n    ...\n\n# Define tasks DAG via an internal DSL\n(\n    brainstorm\n    &gt;&gt; [search_github_for_similar_projects, write_pros_and_cons]\n    &gt;&gt; shortlist_ideas\n)\n</code></pre> <p>Germinate seamlessly takes care of scheduling your tasks, executing them in parallel on multiple processes on multiple computers, and storing/passing results to children tasks etc.</p> </li> <li> <p>Define the Workflow's state machine by defining transitions within states using an internal DSL for state machines</p> <p><pre><code>@ideate.condition()\ndef idea_is_satisfactory(...):\n    ...\n\n\n# Transition to UI design state from ideate state, if the idea is satisfactory\n(\n    (ideate_stage &amp; idea_is_satisfactory)\n    &gt;&gt; ui_design_state\n)\n\n# Transitions are evaluated in order of definition, which can be used to define fallback transitions.\n\n@ideate.condition()\ndef fallback(...):\n    return False\n\n# Transition back to ideate state as a fallback\n(\n    (ideate_stage &amp; fallback)\n    &gt;&gt; ideate_stage\n)\n</code></pre> Note: The parentheses in <code>(&lt;state1&gt; &amp; &lt;condition1&gt;) &gt;&gt; state2</code> are necessary! </p> </li> <li> <p>Use DI to inject the dependencies you need in your task definitions. Use langchain, langgraph etc to execute your multi-agent task. Use pydantic models to specify the input and output schemas.</p> <pre><code>@design_state.task(\n    namespace=\"agent\",\n)\ndef pm_task(\n    input: PMInputSchema,\n    chain_factory=Depends(lc_prompt_chain_factory),\n) -&gt; PMOutputSchema:\n    chain = chain_factory(prompt=PRODUCT_MANAGER_PROMPT)\n\n    output_str = chain.invoke(input.product_requirements)\n    output_json = extract_json_string(output_str)\n\n    prd_document = PRDDocument.model_validate_json(output_json)\n    output = PMOutputSchema(**input.model_dump(), prd_document=prd_document)\n\n    return output\n</code></pre> <pre><code>class PMInputSchema(BaseModel):\n    product_requirements: str\n    \"\"\"Product requirements as specified by the client.\"\"\"\n\n\nclass PRDDocument(BaseModel):\n    product_goals: list[str]\n    \"\"\"List of goals of the product/\"\"\"\n\n    requirements: list[str]\n    \"\"\"List of requirements.\"\"\"\n\n    user_stories: list[str]\n    \"\"\"User stories.\"\"\"\n\n\nclass PMOutputSchema(PMInputSchema):\n    prd_document: PRDDocument\n    \"\"\"Product requirement document.\"\"\"\n</code></pre> </li> </ol>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>.\n\u251c\u2500\u2500 docker                          # Dockerfiles\n\u251c\u2500\u2500 docs                            # Mkdocs Documentation\n\u251c\u2500\u2500 germinate_ai                    # Package source files\n    |\u2500\u2500 api                         # REST API\n    |\u2500\u2500 cli\n    |\u2500\u2500 config                      # Configuration\n    |\u2500\u2500 coordinator                 # Coordinates workflow runs\n    |\u2500\u2500 core                        # Common\n        |\u2500\u2500 exceptions\n        |\u2500\u2500 loader                  # Load workflow specs\n        |\u2500\u2500 states                  # State spec\n        |\u2500\u2500 tasks                   # Task spec\n        |\u2500\u2500 workflows               # Workflow spec\n    |\u2500\u2500 data                        # Persistence\n        |\u2500\u2500 database                # Postgres connectors\n        |\u2500\u2500 models                  # SQLAlchemy models\n        |\u2500\u2500 repositories            # SQLAlchemy CRUD\n        |\u2500\u2500 schemas                 # Pydantic schemas\n    |\u2500\u2500 message_bus                 # Message Bus\n    |\u2500\u2500 memory                      # Interfaces and DI factories for Weaviate, NATS KV\n    |\u2500\u2500 toolbox                     # Helpers, and algorithms\n    |\u2500\u2500 utils\n    |\u2500\u2500 worker                      # Task running worker\n    |\u2500\u2500 workflows                   # Runnable Workflow specifications (Temp - see below)\n\u251c\u2500\u2500 postgres                        # Postgres configuration\n\u251c\u2500\u2500 tests\n</code></pre>"},{"location":"main-ideas/","title":"Main Ideas","text":""},{"location":"main-ideas/#main-ideas","title":"Main Ideas","text":"<p>Parallel execution for IO (asyncio) or CPU bound (multiprocessing + cluster computing) to enable all kinds of creative mixing and matching between LLM based agents, </p> <p>Data flow through task dependency DAGs, and state machines with each state corresponding to a DAG.</p> <p>Formalized (schematized) dialogue between agents through (NATS based) message bus.</p> <p>Simple Dependency Injection to enable flexible agent self improvement by using NATS, Postgres and/or Weaviate vector database as memory stores.</p>"},{"location":"main-ideas/#motivation","title":"Motivation","text":"<p>Inspired by a short talk by Andrew Ng on the potential of multi-agent systems, and reading up on Langchain's LCEL, Langgraph, Autogen, GPTSwarm, MetaGPT, LLM based genetic programming etc, I wanted to try to build something that combined</p> <ul> <li>distributed computing to allow easy parallelization of LLM based (calling remote LLMs or running your own open source ones locally) and non-LLM based (e.g. ML, classical AI algorithms) workflows</li> <li>iterative workflows using HSMs e.g. the write code - run it - re-write it based on error messages etc, which can eventually be extended to implement genetic programming loops (initialization, evaluation, LMX based mutation, and so on...)</li> <li>schematized dialogue -- i.e. the standard operating procedure SOP based approach used by MetaGPT combined with inter-agent  (or inter-task where each task contains langchain/langgraph agents/agent teams) communication NATS as a messaging bus</li> <li>defining steps in multi-agent workflows using dependency injection and state-less execution similar to web frameworks like FastAPI</li> <li>intuitive internal DSLs for defining workflows used by Apache Airflow</li> </ul> <p>There's still a long way to go to get to all this :)</p>"},{"location":"main-ideas/#features","title":"Features","text":""},{"location":"main-ideas/#current","title":"Current","text":"<ul> <li>Specify your multi-agent workflows using intuitive internal DSL to define Data Flow DAGs and State Machines (WIP).</li> <li>Specify your workflows as parallelized tasks with A. schematized inputs/outputs (a la MetaGPT) and B. FastAPI style dependency injection so you can use mix and match how you use message bus channels, Weaviate collections, distributed KV stores in your agent or multi-agent based task.</li> <li>Parallelize workflows with multiple processes single machine, or scale on a cluster.</li> <li>In addition to schematized dataflow between state machine states and task DAGS, also support ad hoc communications between agents using a NATS based messaging bus.</li> <li>Combine large proprietary LLMs with small open source LLMs (Large LLMs are tool-makers/library writes, small LLMs as tool runners). (Partial)</li> <li>Combine IO bound, CPU bound, and GPU bound tasks into your multi-agent workflows. (1. ML + classical AI + LLM-MAS + Anything (E.g. multimedia processing) 2. ... 3. Profit?)</li> </ul>"},{"location":"main-ideas/#planned","title":"Planned","text":"<ul> <li>Easy to implement agent self-improvement, persistence and memory with NATS Key Value store, Postgres and Weaviate (Vector) Databases.</li> <li>Formalized (schematized) dialog (a la MetaGPT), or natural language (a la Autogen) between agents using ad hoc messaging channels. (Partial)</li> <li>Let your LLM based multi-agent workflows create and/or modify your LLM based multi-agent workflows...</li> </ul>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#requirements","title":"Requirements","text":"<ul> <li>A running NATS.io cluster</li> <li>A running Postgres DB (See included <code>docker-compose.yml</code> file)</li> <li>Poetry</li> <li>(Optional for now) A Weaviate instance (See included <code>docker-compose.yml</code> file)</li> </ul>"},{"location":"quickstart/#quickstart","title":"Quickstart","text":"<ol> <li> <p>Clone the repo, and install dependencies with poetry.</p> <pre><code>poetry install\n</code></pre> </li> <li> <p>Run the NATS Jetstream cluster.</p> <p>You can simply use the NATS CLI to run a test cluster: <pre><code>nats server --jetstream\n</code></pre></p> </li> <li> <p>Run Postgres.</p> <p>You can use the included <code>docker-compose.yml</code> file: <pre><code>docker compose --profile postgres up -d\n</code></pre></p> </li> <li> <p>Create a <code>.env</code> file in <code>./</code> based on the included <code>.env.example</code> file.</p> </li> <li> <p>Run the coordinator process.</p> <pre><code>poetry run germinate coordinator\n</code></pre> <p>The coordinator updates state, and triggers state transitions/enqueues tasks as appropriate based on your Workflow state machine + tasks DAGs definitions.</p> </li> <li> <p>Run one or more workers.</p> <pre><code>poetry run germinate worker\n</code></pre> <p>Workers execute tasks that are assigned to them.</p> </li> <li> <p>Run a workflow.</p> <pre><code>poetry run germinate workflow germinate_ai.workflows.metagpt.main '{\"product_requirements\": \"A simple tictactoe game using Pygame\"}' \n</code></pre> </li> </ol> <p>TEMP: Ideally, you would be able to create workflows in your own project and use Germinate as a framework. But, until we implement pickling and sending task executors over the wire to remote workers, its easiest to write workflows in <code>./germinate_ai/workflows</code> and execute them as shown above.</p> <p>The last argument is the input to the first set of tasks in the workflows initial state's tasks DAG.</p> <p>Refer to <code>./germinate_ai/workflows/metagpt</code> to see our (WIP) first example workflow.</p>"},{"location":"quickstart/#commands","title":"Commands","text":"<p>Temporary limited CLI:</p> <ul> <li><code>germinate coordinator</code> - Start the Coordinator process.</li> <li><code>germinate worker</code> - Start the Worker process.</li> <li><code>germinate workflow germinate_ai.workflows.metagpt.main</code> - Enqueue the simple MetaGPT-(ish) workflow.</li> <li><code>germinate db</code> - Create all Postgres tables.</li> <li><code>germinate --help</code> - Print help message and exit.</li> </ul>"},{"location":"reference/coordinator/","title":"Coordinator","text":""},{"location":"reference/coordinator/#coordinator","title":"Coordinator","text":""},{"location":"reference/coordinator/#germinate_ai.coordinator.coordinator.Coordinator","title":"<code>Coordinator</code>","text":"<p>Polls task completions and updates corresponding state.</p> Source code in <code>germinate_ai/coordinator/coordinator.py</code> <pre><code>@attr.define(init=False)\nclass Coordinator:\n    \"\"\"Polls task completions and updates corresponding state.\"\"\"\n\n    nc: nats.NatsConnection\n    db: Session\n    tick_interval: int\n    scheduler: Scheduler\n    completions_queue: NATSQueue\n\n    def __init__(\n        self, nc: nats.NatsConnection, db: Session, scheduler: Scheduler, tick_interval: int = 10\n    ):\n        self.nc = nc\n        self.db = db\n        self.tick_interval = tick_interval\n        self.scheduler = scheduler\n\n    async def run(self):\n        \"\"\"Connect to message bus, wait for task completion notifications, and update state/schedule tasks accordingly.\"\"\"\n\n        next_tick = get_next_tick(self.tick_interval)\n\n        await self.connect()\n        logger.success(\n            \"Coordinator connected to cluster! Waiting for task completions...\"\n        )\n\n        while True:\n            last_tick = time.time()\n\n            try:\n                msg = await self.completions_queue.dequeue()\n                task_json = msg.data\n                # ack message so we don't see it again\n                await msg.ack()\n                await self._handle_task_completion(task_json)                    \n            except TimeoutError:\n                pass\n            except asyncio.CancelledError:\n                logger.debug(\n                    \"Worker #{self.id}: Cancelled! Shutting down coordinator...\"\n                )\n                break\n            except Exception as e:\n                logger.exception(\"Error while reading from NATS queue: \", e)\n\n            await asyncio.sleep(next_tick(last_tick=last_tick))\n\n    async def connect(self):\n        \"\"\"Connect to get task completion notifications.\"\"\"\n        self.completions_queue = NATSQueue(\n            stream=\"jobs\",\n            subject=\"jobs.task_completions\",\n            durable_consumer=\"coordinator\",\n            connection=self.nc,\n        )\n        await self.completions_queue.connect()\n\n        await self.scheduler.connect()\n\n    async def _handle_task_completion(self, task_json: str) -&gt; bool:\n        # TODO too long - refactor!!\n\n        try:\n            logger.debug(f\"Handling message: `{task_json}`\")\n            assignment = TaskAssignment.model_validate_json(task_json)\n        except ValidationError as e:\n            logger.error(f\"Skipping invalid task `{task_json}`: {e}\")\n            return True\n\n        # # Get corresponding Task from DB\n        # task = get_task_instance_from_assignment(self.db, assignment)\n        # if task is None:\n        #     logger.error(f\"No such task: skipping `{assignment}`\")\n        #     return True\n\n        # Get corresponding State from DB\n        state_instance = get_state(self.db, assignment.state_instance_id)\n        if state_instance is None:\n            logger.error(f\"Skipping invalid state_instance `{assignment.state_instance_id}`\")\n            return\n\n        # Is current phase still incomplete?\n        if not state_instance.current_phase_complete:\n            # More tasks remaining in this state phase, so don't do anything\n            return True\n\n        # Are there unscheduled phases remaining in this state?\n        if not state_instance.all_phases_complete:\n            logger.debug(f\"Queuing next phases in state {state_instance.name} complete.\")\n            # Enqueue next phase and return\n            state_instance.next_phase()\n            await self._enqueue_state_phase(state_instance)\n            return True\n\n\n        # All tasks in state's tasks DAG are complete!\n        logger.debug(f\"State {state_instance.name} completed!\")\n        if state_instance.state == StateInstanceStateEnum.completed:\n            logger.debug(f\"Looks like {state_instance.name} was already marked as completed. Skipping...\")\n            return\n\n\n\n        # Get workflow run\n        workflow_run = get_workflow_run(self.db, state_instance.workflow_run_id)\n\n        # Figure out transition to next state\n        # (Uses condition evaluation results from DB)\n        next_state_name = state_instance.next_state()\n        if next_state_name is None:\n            # Update workflow run state and finish\n\n            # TODO refactor\n\n            # Completed workflow\n            logger.success(f\"Workflow run {workflow_run.workflow_name}#v{workflow_run.workflow_version} completed!\")\n\n            # Combine output from final phase of last state\n            final_output = state_instance.state_output()\n            # Save it in workflow run entry\n            workflow_run.output = final_output\n\n            workflow_run.state = WorkflowRunStateEnum.completed\n            self.db.add(workflow_run)\n\n            # Update state instance state\n            state_instance.state = StateInstanceStateEnum.completed\n            self.db.add(state_instance)\n            self.db.commit()\n\n            return\n\n\n        logger.debug(f\"Transition from {state_instance.name} to {next_state_name}\")\n\n        # get next state instance\n        next_state_instance = workflow_run.state_instance_by_name(next_state_name)\n\n        # Get combined output from prev state for next state's input\n        next_state_input = state_instance.state_output()\n        # print(next_state_input)\n\n        # TODO refactor\n        # store input to first phase tasks\n        nq = NATSQueue(\n            connection=self.nc,\n            stream=\"jobs\",\n            subject=f\"jobs.{next_state_instance.id}.from_start.to_descendant\",\n        )\n        await nq.connect()\n        msg = Message(source=\"start\", payload=next_state_input)\n        await nq.enqueue(msg.model_dump_json())\n        #\n\n        # Update state instance state\n        state_instance.state = StateInstanceStateEnum.completed\n        self.db.add(state_instance)\n\n        # Transition workflow run to next state\n        workflow_run.current_state = next_state_instance\n        self.db.add(workflow_run)\n        self.db.commit()\n\n        # Enqueue the first phase in new state\n        await self._enqueue_state_phase(next_state_instance)\n\n\n    async def _enqueue_state_phase(self, state: StateInstance):\n        # Enter next phase in state\n        await self.scheduler.enqueue_tasks(state.phase_tasks)\n        # update state instance\n        self.db.add(state)\n        self.db.commit()\n</code></pre>"},{"location":"reference/coordinator/#germinate_ai.coordinator.coordinator.Coordinator.connect","title":"<code>connect()</code>  <code>async</code>","text":"<p>Connect to get task completion notifications.</p> Source code in <code>germinate_ai/coordinator/coordinator.py</code> <pre><code>async def connect(self):\n    \"\"\"Connect to get task completion notifications.\"\"\"\n    self.completions_queue = NATSQueue(\n        stream=\"jobs\",\n        subject=\"jobs.task_completions\",\n        durable_consumer=\"coordinator\",\n        connection=self.nc,\n    )\n    await self.completions_queue.connect()\n\n    await self.scheduler.connect()\n</code></pre>"},{"location":"reference/coordinator/#germinate_ai.coordinator.coordinator.Coordinator.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Connect to message bus, wait for task completion notifications, and update state/schedule tasks accordingly.</p> Source code in <code>germinate_ai/coordinator/coordinator.py</code> <pre><code>async def run(self):\n    \"\"\"Connect to message bus, wait for task completion notifications, and update state/schedule tasks accordingly.\"\"\"\n\n    next_tick = get_next_tick(self.tick_interval)\n\n    await self.connect()\n    logger.success(\n        \"Coordinator connected to cluster! Waiting for task completions...\"\n    )\n\n    while True:\n        last_tick = time.time()\n\n        try:\n            msg = await self.completions_queue.dequeue()\n            task_json = msg.data\n            # ack message so we don't see it again\n            await msg.ack()\n            await self._handle_task_completion(task_json)                    \n        except TimeoutError:\n            pass\n        except asyncio.CancelledError:\n            logger.debug(\n                \"Worker #{self.id}: Cancelled! Shutting down coordinator...\"\n            )\n            break\n        except Exception as e:\n            logger.exception(\"Error while reading from NATS queue: \", e)\n\n        await asyncio.sleep(next_tick(last_tick=last_tick))\n</code></pre>"},{"location":"reference/coordinator/#scheduler","title":"Scheduler","text":""},{"location":"reference/coordinator/#germinate_ai.coordinator.scheduler.Scheduler","title":"<code>Scheduler</code>","text":"<p>Enqueue tasks ready to be assigned to workers.</p> Source code in <code>germinate_ai/coordinator/scheduler.py</code> <pre><code>@attr.define(init=False)\nclass Scheduler:\n    \"\"\"Enqueue tasks ready to be assigned to workers.\"\"\"\n\n    nc: nats.NatsConnection\n    connected: bool\n    assignments_queue: NATSQueue\n\n    def __init__(self, nc: nats.NatsConnection):\n        self.nc = nc\n        self.connected = False\n\n    async def connect(self):\n        \"\"\"Connect to task assignments queue.\"\"\"\n        if self.connected:\n            return\n\n        self.assignments_queue = NATSQueue(\n            stream=\"jobs\",\n            subject=\"jobs.task_assignments\",\n            connection=self.nc,\n        )\n        await self.assignments_queue.connect()\n        self.connected = True\n\n    async def enqueue_tasks(self, tasks: typ.Sequence[TaskInstance]):\n        \"\"\"Enqueue a sequence of tasks.\n\n        Creates `TaskAssignment`s for each task and adds it to the distributed queue.\n        \"\"\"\n        if not self.connected:\n            await self.connect()\n\n        for task in tasks:\n            logger.debug(f\"Queueing {task.name}\")\n            # create assignment and add it to the queue\n            assignment = TaskAssignment(\n                state_instance_id=task.state_instance_id, name=task.name\n            )\n            await self.assignments_queue.enqueue(assignment.model_dump_json())\n\n    async def enqueue_state(self, state: StateInstance):\n        \"\"\"Enqueue the next phase (tasks that can be run in parallel) of the given state.\n\n        Note: Assumes all the related task instances are accessible in `state`.\n        \"\"\"\n        # sanity check\n        if state.current_phase_index &gt; len(state.sorted_tasks_phases) - 1:\n            raise IndexError(f\"State {state.name}'s current phase {state.current_phase_index} out of bounds\")\n        # get names of tasks in current phase\n        task_names = set(state.sorted_tasks_phases[state.current_phase_index])\n        # filter out corresponding tasks \n        tasks = [task for task in state.task_instances if task.name in task_names]\n        # enqueue the tasks\n        await self.enqueue_tasks(tasks)\n</code></pre>"},{"location":"reference/coordinator/#germinate_ai.coordinator.scheduler.Scheduler.connect","title":"<code>connect()</code>  <code>async</code>","text":"<p>Connect to task assignments queue.</p> Source code in <code>germinate_ai/coordinator/scheduler.py</code> <pre><code>async def connect(self):\n    \"\"\"Connect to task assignments queue.\"\"\"\n    if self.connected:\n        return\n\n    self.assignments_queue = NATSQueue(\n        stream=\"jobs\",\n        subject=\"jobs.task_assignments\",\n        connection=self.nc,\n    )\n    await self.assignments_queue.connect()\n    self.connected = True\n</code></pre>"},{"location":"reference/coordinator/#germinate_ai.coordinator.scheduler.Scheduler.enqueue_state","title":"<code>enqueue_state(state)</code>  <code>async</code>","text":"<p>Enqueue the next phase (tasks that can be run in parallel) of the given state.</p> <p>Note: Assumes all the related task instances are accessible in <code>state</code>.</p> Source code in <code>germinate_ai/coordinator/scheduler.py</code> <pre><code>async def enqueue_state(self, state: StateInstance):\n    \"\"\"Enqueue the next phase (tasks that can be run in parallel) of the given state.\n\n    Note: Assumes all the related task instances are accessible in `state`.\n    \"\"\"\n    # sanity check\n    if state.current_phase_index &gt; len(state.sorted_tasks_phases) - 1:\n        raise IndexError(f\"State {state.name}'s current phase {state.current_phase_index} out of bounds\")\n    # get names of tasks in current phase\n    task_names = set(state.sorted_tasks_phases[state.current_phase_index])\n    # filter out corresponding tasks \n    tasks = [task for task in state.task_instances if task.name in task_names]\n    # enqueue the tasks\n    await self.enqueue_tasks(tasks)\n</code></pre>"},{"location":"reference/coordinator/#germinate_ai.coordinator.scheduler.Scheduler.enqueue_tasks","title":"<code>enqueue_tasks(tasks)</code>  <code>async</code>","text":"<p>Enqueue a sequence of tasks.</p> <p>Creates <code>TaskAssignment</code>s for each task and adds it to the distributed queue.</p> Source code in <code>germinate_ai/coordinator/scheduler.py</code> <pre><code>async def enqueue_tasks(self, tasks: typ.Sequence[TaskInstance]):\n    \"\"\"Enqueue a sequence of tasks.\n\n    Creates `TaskAssignment`s for each task and adds it to the distributed queue.\n    \"\"\"\n    if not self.connected:\n        await self.connect()\n\n    for task in tasks:\n        logger.debug(f\"Queueing {task.name}\")\n        # create assignment and add it to the queue\n        assignment = TaskAssignment(\n            state_instance_id=task.state_instance_id, name=task.name\n        )\n        await self.assignments_queue.enqueue(assignment.model_dump_json())\n</code></pre>"},{"location":"reference/memory/","title":"Memory","text":""},{"location":"reference/memory/#nats-kv","title":"NATS KV","text":""},{"location":"reference/memory/#germinate_ai.memory.kv.KeyValueStore","title":"<code>KeyValueStore</code>","text":"<p>NATS Key Value Store</p> Source code in <code>germinate_ai/memory/kv.py</code> <pre><code>class KeyValueStore:\n    \"\"\"NATS Key Value Store\"\"\"\n\n    connected: bool = False\n    kv: _KeyValue = None\n\n    def __init__(self, bucket_name: str, connection: NatsConnection = None):\n        self.bucket_name = bucket_name\n        if connection is None:\n            connection = NatsConnection()\n        self.connection = connection\n\n\n    async def connect(self):\n        \"\"\"Connect to NATS cluster.\"\"\"\n        if not self.connection.is_connected:\n            await self.connection.connect()\n        self.kv = await self.connection.jetstream.create_key_value(bucket=self.bucket_name)\n        self.connected = True\n\n    async def get(self, key: str) -&gt; str:\n        \"\"\"Get value corresponding to key.\"\"\"\n        entry =  await self.kv.get(key)\n        return entry.value.decode()\n\n    async def put(self, key: str, value: str):\n        \"\"\"Store key, value in store.\"\"\" \n        await self.kv.put(key, value.encode())\n</code></pre>"},{"location":"reference/memory/#germinate_ai.memory.kv.KeyValueStore.connect","title":"<code>connect()</code>  <code>async</code>","text":"<p>Connect to NATS cluster.</p> Source code in <code>germinate_ai/memory/kv.py</code> <pre><code>async def connect(self):\n    \"\"\"Connect to NATS cluster.\"\"\"\n    if not self.connection.is_connected:\n        await self.connection.connect()\n    self.kv = await self.connection.jetstream.create_key_value(bucket=self.bucket_name)\n    self.connected = True\n</code></pre>"},{"location":"reference/memory/#germinate_ai.memory.kv.KeyValueStore.get","title":"<code>get(key)</code>  <code>async</code>","text":"<p>Get value corresponding to key.</p> Source code in <code>germinate_ai/memory/kv.py</code> <pre><code>async def get(self, key: str) -&gt; str:\n    \"\"\"Get value corresponding to key.\"\"\"\n    entry =  await self.kv.get(key)\n    return entry.value.decode()\n</code></pre>"},{"location":"reference/memory/#germinate_ai.memory.kv.KeyValueStore.put","title":"<code>put(key, value)</code>  <code>async</code>","text":"<p>Store key, value in store.</p> Source code in <code>germinate_ai/memory/kv.py</code> <pre><code>async def put(self, key: str, value: str):\n    \"\"\"Store key, value in store.\"\"\" \n    await self.kv.put(key, value.encode())\n</code></pre>"},{"location":"reference/memory/#germinate_ai.memory.kv.kv_story_factory","title":"<code>kv_story_factory(*, bucket_name, connection=None)</code>","text":"<p>Creates a KV store.</p> Source code in <code>germinate_ai/memory/kv.py</code> <pre><code>def kv_story_factory(*, bucket_name: str, connection: NatsConnection = None):\n    \"\"\"Creates a KV store.\"\"\"\n    kv = KeyValueStore(bucket_name, connection=connection)\n    return kv\n</code></pre>"},{"location":"reference/memory/#weaviate","title":"Weaviate","text":""},{"location":"reference/memory/#germinate_ai.memory.weaviate.WeaviateCollection","title":"<code>WeaviateCollection</code>","text":"<p>Adapter for a Weaviate collection.</p> Source code in <code>germinate_ai/memory/weaviate.py</code> <pre><code>class WeaviateCollection:\n    \"\"\"Adapter for a Weaviate collection.\"\"\"\n\n    def __init__(self, collection_name: str, *, host: str, port: str, grpc_port: int):\n        self.collection_name = collection_name\n        self.host = host\n        self.port = port\n        self.grpc_port = grpc_port\n        self.client = None\n        self.collection = None\n\n    def connect(self):\n        \"\"\"Connect to Weaviate.\"\"\"\n        self.client = weaviate.connect_to_local(\n            host=self.host,\n            port=self.port,\n            grpc_port=self.grpc_port,\n        )\n\n    def create_collection(self):\n        \"\"\"Create a Weaviate collection.\"\"\"\n        self.collection = self.client.collections.create(\n            name=self.collection_name,\n            vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n            vector_index_config=wvc.config.Configure.VectorIndex.hnsw(\n                distance_metric=wvc.config.VectorDistances.COSINE  # select prefered distance metric\n            ),\n        )\n\n    def query_near_vector(\n        self, query_vector: typ.Sequence[float], *, filters=None, limit=10\n    ):\n        \"\"\"Search by query vector.\"\"\"\n        resp = self.collection.query.near_vector(\n            near_vector=query_vector,\n            limit=limit,\n            return_metadata=wvc.query.MetadataQuery(certainty=True),\n            filters=filters,\n        )\n        return resp\n</code></pre>"},{"location":"reference/memory/#germinate_ai.memory.weaviate.WeaviateCollection.connect","title":"<code>connect()</code>","text":"<p>Connect to Weaviate.</p> Source code in <code>germinate_ai/memory/weaviate.py</code> <pre><code>def connect(self):\n    \"\"\"Connect to Weaviate.\"\"\"\n    self.client = weaviate.connect_to_local(\n        host=self.host,\n        port=self.port,\n        grpc_port=self.grpc_port,\n    )\n</code></pre>"},{"location":"reference/memory/#germinate_ai.memory.weaviate.WeaviateCollection.create_collection","title":"<code>create_collection()</code>","text":"<p>Create a Weaviate collection.</p> Source code in <code>germinate_ai/memory/weaviate.py</code> <pre><code>def create_collection(self):\n    \"\"\"Create a Weaviate collection.\"\"\"\n    self.collection = self.client.collections.create(\n        name=self.collection_name,\n        vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n        vector_index_config=wvc.config.Configure.VectorIndex.hnsw(\n            distance_metric=wvc.config.VectorDistances.COSINE  # select prefered distance metric\n        ),\n    )\n</code></pre>"},{"location":"reference/memory/#germinate_ai.memory.weaviate.WeaviateCollection.query_near_vector","title":"<code>query_near_vector(query_vector, *, filters=None, limit=10)</code>","text":"<p>Search by query vector.</p> Source code in <code>germinate_ai/memory/weaviate.py</code> <pre><code>def query_near_vector(\n    self, query_vector: typ.Sequence[float], *, filters=None, limit=10\n):\n    \"\"\"Search by query vector.\"\"\"\n    resp = self.collection.query.near_vector(\n        near_vector=query_vector,\n        limit=limit,\n        return_metadata=wvc.query.MetadataQuery(certainty=True),\n        filters=filters,\n    )\n    return resp\n</code></pre>"},{"location":"reference/message-bus/","title":"Message Bus","text":""},{"location":"reference/message-bus/#messaging-channels","title":"Messaging Channels","text":""},{"location":"reference/message-bus/#germinate_ai.message_bus.NATSQueue","title":"<code>NATSQueue</code>","text":"<p>             Bases: <code>AbstractMessageQueue[Generic[T]]</code>, <code>ABC</code></p> <p>A distributed message queue on top of NATS Jetstream.</p> Source code in <code>germinate_ai/message_bus/message_queue.py</code> <pre><code>class NATSQueue(AbstractMessageQueue[Generic[T]], ABC):\n    \"\"\"A distributed message queue on top of NATS Jetstream.\"\"\"\n\n    def __init__(\n        self,\n        stream: str,\n        subject: str,\n        durable_consumer: str = None,\n        connection: NatsConnection = None,\n    ):\n        if connection is None:\n            connection = NatsConnection()\n        self.connection = connection\n        self.stream = stream\n        self.subject = subject\n        self.durable_consumer = durable_consumer\n        self.consumer = None\n\n    async def connect(self):\n        if not self.connection.is_connected:\n            await self.connection.connect()\n        # if self.durable_consumer is not None:\n        self.consumer = await self.connection.jetstream.pull_subscribe(\n            stream=self.stream,\n            subject=self.subject,\n            durable=self.durable_consumer,\n        )\n\n    async def enqueue(self, item: T):\n        await self.connection.jetstream.publish(self.subject, item.encode())\n\n    async def dequeue(self) -&gt; Msg:\n        # Callers are responsible for acknowledging with `await msg.ack()` call!!\n        msgs = await self.consumer.fetch(batch=1)\n        for msg in msgs:\n            msg.data = msg.data.decode()\n            return msg\n\n    async def aiter_dequeue(self) -&gt; AsyncGenerator[T, None]:\n        msgs = await self.consumer.fetch(batch=1)\n        for msg in msgs:\n            # bytes -&gt; str\n            msg.data = msg.data.decode()\n            yield msg\n            await msg.ack()\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.NatsConnection","title":"<code>NatsConnection</code>","text":"<p>NATS connection singleton class.</p> Source code in <code>germinate_ai/message_bus/nats/connection.py</code> <pre><code>class NatsConnection:\n    \"\"\"NATS connection singleton class.\"\"\"\n\n    _instance: \"NatsConnection\" = None\n\n    def __new__(cls, nats_url=NATS_URL) -&gt; \"NatsConnection\":\n        if cls._instance is None:\n            logger.debug(f\"Creating a new NATS connection to cluster: `{nats_url}`...\")\n            cls._instance = super().__new__(cls)\n        return cls._instance\n\n    def __init__(self, nats_url=NATS_URL):\n        self.nats_url = nats_url\n        self.nc = None\n        self.jetstream = None\n\n    @property\n    def is_connected(self) -&gt; bool:\n        if self.nc is None:\n            return False\n        return self.nc.is_connected\n\n    async def connect(self):\n        # Connect if necessary\n        if self.nc is None:\n            self.nc = await nats.connect(self.nats_url)\n        # Jetstream context\n        if self.jetstream is None:\n            self.jetstream = self.nc.jetstream()\n\n    async def close(self):\n        await self.nc.close()\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.ROMessageChannel","title":"<code>ROMessageChannel</code>","text":"<p>             Bases: <code>AbstractMessageChannel</code></p> <p>A Read Only Message Channel</p> Source code in <code>germinate_ai/message_bus/message_channels.py</code> <pre><code>class ROMessageChannel(AbstractMessageChannel):\n    \"\"\"A Read Only Message Channel\"\"\"\n\n    consumer: JetStreamContext.PullSubscription\n\n    async def connect(self):\n        \"\"\"Connect to the message bus.\"\"\"\n        await super().connect()\n        self.consumer = await self.connection.jetstream.pull_subscribe(\n            stream=self.stream,\n            subject=self.subject,\n            durable=self.durable_consumer,\n        )\n\n    async def read(self, batch: int = 1) -&gt; typ.Sequence[Msg]:\n        \"\"\"Read `batch` messages from the channel.\"\"\"\n        if not self.connected:\n            await self.connect()\n        msgs = await self.consumer.fetch(batch=batch)\n        for msg in msgs:\n            msg.data = msg.data.decode()\n        return msgs\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.ROMessageChannel.connect","title":"<code>connect()</code>  <code>async</code>","text":"<p>Connect to the message bus.</p> Source code in <code>germinate_ai/message_bus/message_channels.py</code> <pre><code>async def connect(self):\n    \"\"\"Connect to the message bus.\"\"\"\n    await super().connect()\n    self.consumer = await self.connection.jetstream.pull_subscribe(\n        stream=self.stream,\n        subject=self.subject,\n        durable=self.durable_consumer,\n    )\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.ROMessageChannel.read","title":"<code>read(batch=1)</code>  <code>async</code>","text":"<p>Read <code>batch</code> messages from the channel.</p> Source code in <code>germinate_ai/message_bus/message_channels.py</code> <pre><code>async def read(self, batch: int = 1) -&gt; typ.Sequence[Msg]:\n    \"\"\"Read `batch` messages from the channel.\"\"\"\n    if not self.connected:\n        await self.connect()\n    msgs = await self.consumer.fetch(batch=batch)\n    for msg in msgs:\n        msg.data = msg.data.decode()\n    return msgs\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.RWMessageChannel","title":"<code>RWMessageChannel</code>","text":"<p>             Bases: <code>WOMessageChannel</code>, <code>ROMessageChannel</code></p> <p>A Read/Write Message Channel</p> Source code in <code>germinate_ai/message_bus/message_channels.py</code> <pre><code>class RWMessageChannel(WOMessageChannel, ROMessageChannel):\n    \"A Read/Write Message Channel\"\n\n    pass\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.WOMessageChannel","title":"<code>WOMessageChannel</code>","text":"<p>             Bases: <code>AbstractMessageChannel</code></p> <p>A Write Only Message Channel</p> Source code in <code>germinate_ai/message_bus/message_channels.py</code> <pre><code>class WOMessageChannel(AbstractMessageChannel):\n    \"A Write Only Message Channel\"\n\n    def __init__(\n        self,\n        stream: str,\n        subject: str,\n        durable_consumer: str = None,\n        connection: NatsConnection = None,\n    ):\n        if not _validate_write_subject(subject):\n            raise ValueError(f\"Invalid subject {subject} for write channel\")\n\n        self.subject = subject\n        if connection is None:\n            connection = NatsConnection()\n        self.connection = connection\n        self.stream = stream\n        self.durable_consumer = durable_consumer\n\n    async def write(self, msg: str):\n        \"\"\"Write the string `msg` into the message bus.\"\"\"\n        await self.connection.jetstream.publish(self.subject, msg.encode())\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.WOMessageChannel.write","title":"<code>write(msg)</code>  <code>async</code>","text":"<p>Write the string <code>msg</code> into the message bus.</p> Source code in <code>germinate_ai/message_bus/message_channels.py</code> <pre><code>async def write(self, msg: str):\n    \"\"\"Write the string `msg` into the message bus.\"\"\"\n    await self.connection.jetstream.publish(self.subject, msg.encode())\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.nats_connection","title":"<code>nats_connection(nats_url=NATS_URL)</code>  <code>async</code>","text":"<p>NATS connection context manager that opens and closes the connection for you.</p> Source code in <code>germinate_ai/message_bus/nats/connection.py</code> <pre><code>@asynccontextmanager\nasync def nats_connection(nats_url=NATS_URL):\n    \"\"\"NATS connection context manager that opens and closes the connection for you.\"\"\"\n    nc = NatsConnection(nats_url=nats_url)\n    await nc.connect()\n    yield nc\n    await nc.close()\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.ro_message_channel_factory","title":"<code>ro_message_channel_factory(stream, subject, durable_consumer=None, connection=None)</code>","text":"<p>Create a Read Only Message Channel</p> Source code in <code>germinate_ai/message_bus/factories.py</code> <pre><code>def ro_message_channel_factory(\n    stream, subject, durable_consumer=None, connection=None\n) -&gt; ROMessageChannel:\n    \"\"\"Create a Read Only Message Channel\"\"\"\n    chan = ROMessageChannel(\n        stream=stream,\n        subject=subject,\n        durable_consumer=durable_consumer,\n        connection=connection,\n    )\n    return chan\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.rw_message_channel_factory","title":"<code>rw_message_channel_factory(stream, subject, durable_consumer=None, connection=None)</code>","text":"<p>Create a Read Only Message Channel</p> Source code in <code>germinate_ai/message_bus/factories.py</code> <pre><code>def rw_message_channel_factory(\n    stream, subject, durable_consumer=None, connection=None\n) -&gt; ROMessageChannel:\n    \"\"\"Create a Read Only Message Channel\"\"\"\n    chan = RWMessageChannel(\n        stream=stream,\n        subject=subject,\n        durable_consumer=durable_consumer,\n        connection=connection,\n    )\n    return chan\n</code></pre>"},{"location":"reference/message-bus/#germinate_ai.message_bus.wo_message_channel_factory","title":"<code>wo_message_channel_factory(stream, subject, durable_consumer=None, connection=None)</code>","text":"<p>Create a Read Only Message Channel</p> Source code in <code>germinate_ai/message_bus/factories.py</code> <pre><code>def wo_message_channel_factory(\n    stream, subject, durable_consumer=None, connection=None\n) -&gt; ROMessageChannel:\n    \"\"\"Create a Read Only Message Channel\"\"\"\n    chan = WOMessageChannel(\n        stream=stream,\n        subject=subject,\n        durable_consumer=durable_consumer,\n        connection=connection,\n    )\n    return chan\n</code></pre>"},{"location":"reference/utils/","title":"Utils","text":""},{"location":"reference/utils/#dependency-injection","title":"Dependency Injection","text":""},{"location":"reference/utils/#germinate_ai.utils.di.Depends","title":"<code>Depends</code>","text":"<p>Simple Dependency injection implementation similar to FastAPI.</p> Source code in <code>germinate_ai/utils/di.py</code> <pre><code>class Depends:\n    \"\"\"Simple Dependency injection implementation similar to FastAPI.\"\"\"\n\n    _cache: dict[Callable, typ.Any] = {}\n\n    def __init__(self, dependency: Callable, *args: typ.Any, **kwargs: typ.Any):\n        self.dependency = dependency\n        self.args = args\n        self.kwargs = kwargs\n\n    def __call__(self) -&gt; typ.Any:\n        if self.dependency in Depends._cache:\n            return Depends._cache[self.dependency]\n\n        result = self.dependency(*self.args, **self.kwargs)\n        Depends._cache[self.dependency] = result\n        return result\n</code></pre>"},{"location":"reference/utils/#germinate_ai.utils.di.get_io_schemas","title":"<code>get_io_schemas(func)</code>","text":"<p>Get input and output schemas (Pydantic models) from the function signature.</p> Source code in <code>germinate_ai/utils/di.py</code> <pre><code>def get_io_schemas(func: typ.Callable) -&gt; tuple[BaseModel, BaseModel]:\n    \"\"\"Get input and output schemas (Pydantic models) from the function signature.\"\"\"\n    # Get input and output schemas from signature/type hints\n    signature = inspect.signature(func)\n    type_hints = typ.get_type_hints(func)\n\n    # might not take any input/output\n    input_schema = BaseModel\n    output_schema = BaseModel\n\n    if \"input\" in type_hints:\n        input_type = type_hints[\"input\"]\n        if issubclass(input_type, BaseModel):\n            input_schema = input_type\n\n    if signature.return_annotation == signature.empty:\n        # TODO appropriate error type\n        raise TypeError(f\"Task {func.__name__} does not specify an output schema\")\n    if \"return\" in type_hints:\n        output_type = type_hints[\"return\"]\n        if issubclass(output_type, BaseModel):\n            output_schema = output_type\n\n    return input_schema, output_schema\n</code></pre>"},{"location":"reference/utils/#germinate_ai.utils.di.resolve_dependencies","title":"<code>resolve_dependencies(func, *args, **kwargs)</code>","text":"<p>Returns bound arguments with dependencies resolved.</p> Source code in <code>germinate_ai/utils/di.py</code> <pre><code>def resolve_dependencies(func: typ.Callable, *args: typ.Any, **kwargs: typ.Any) -&gt; inspect.BoundArguments:\n    \"\"\"Returns bound arguments with dependencies resolved.\"\"\"\n    sig = inspect.signature(func)\n    bound = sig.bind(*args, **kwargs)\n    bound.apply_defaults()\n\n    for k, arg in bound.arguments.items():\n        if type(arg) == Depends:\n            bound.arguments[k] = arg()\n\n    return bound\n</code></pre>"},{"location":"reference/utils/#germinate_ai.utils.di.resolve_dependencies_wrapper","title":"<code>resolve_dependencies_wrapper(func)</code>","text":"<p>Returns a function wrapper that binds func arguments, applies defaults and resolves any dependency injections.</p> Source code in <code>germinate_ai/utils/di.py</code> <pre><code>def resolve_dependencies_wrapper(func: typ.Callable):\n    \"\"\"Returns a function wrapper that binds func arguments, applies defaults and resolves any dependency injections.\"\"\"\n    if asyncio.iscoroutinefunction(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            bound = resolve_dependencies(func, *args, **kwargs)\n            return await func(*bound.args, **bound.kwargs)\n        return wrapper\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        bound = resolve_dependencies(func, *args, **kwargs)\n        return func(*bound.args, **bound.kwargs)\n    return wrapper\n</code></pre>"},{"location":"reference/utils/#misc","title":"Misc","text":""},{"location":"reference/utils/#germinate_ai.utils.helpers.get_next_tick","title":"<code>get_next_tick(tick_interval)</code>","text":"<p>Given a tick interval (in seconds), returns a function that gives the time to sleep until next tick based on the last tick timestamp.</p> Source code in <code>germinate_ai/utils/helpers.py</code> <pre><code>def get_next_tick(tick_interval: int):\n    \"\"\"Given a tick interval (in seconds), returns a function that gives the time to sleep until next tick based on the last tick timestamp.\"\"\"\n\n    def _next_tick(last_tick: float):\n        time_since = time.time() - last_tick\n        return tick_interval - time_since\n\n    return _next_tick\n</code></pre>"},{"location":"reference/worker/","title":"Worker","text":""},{"location":"reference/worker/#worker","title":"Worker","text":"<p>This module implements a Worker class that waits for task assignments from the message bus, hands over assignments to the TaskDispatcher, and notifies listeners on task completions via the message bus.</p>"},{"location":"reference/worker/#germinate_ai.worker.worker.Worker","title":"<code>Worker</code>","text":"<p>Polls and processes tasks from the assignments queue.</p> Source code in <code>germinate_ai/worker/worker.py</code> <pre><code>class Worker:\n    \"\"\"Polls and processes tasks from the assignments queue.\"\"\"\n\n    def __init__(\n        self,\n        nc: nats.NatsConnection,\n        task_dispatcher: TaskDispatcher,\n        id: int = 0,\n        tick_interval: int = 10,\n    ):\n        self.nc = nc\n        self.id = id\n        self.tick_interval = tick_interval\n        self.task_dispatcher = task_dispatcher\n\n    async def run(self):\n        \"\"\"Connect to messaging bus, wait for assignments, and execute them.\"\"\"\n        next_tick = get_next_tick(self.tick_interval)\n\n        await self.connect()\n        logger.success(f\"Worker #{self.id}: connected to cluster! Waiting for tasks...\")\n\n        while True:\n            last_tick = time.time()\n\n            try:\n                msg = await self.assignments_queue.dequeue()\n                task_json = msg.data\n                # acknowledge message so we don't see it again\n                await msg.ack()\n                success = await self._run_task(task_json)\n                if not success:\n                    logger.exception(\"Task execution failure\", task_json)\n            except TimeoutError:\n                pass\n            except asyncio.CancelledError:\n                logger.debug(f\"Worker #{self.id}: Cancelled! Shutting down worker...\")\n                break\n            except Exception as e:\n                logger.exception(\"Error while reading from NATS queue: \", e)\n\n            await asyncio.sleep(next_tick(last_tick=last_tick))\n\n    async def connect(self):\n        \"\"\"Connect to task assignments and completions queue so we can get assignments/send task completion notifications via the message bus.\"\"\"\n        self.assignments_queue = NATSQueue(\n            stream=\"jobs\",\n            subject=\"jobs.task_assignments\",\n            durable_consumer=\"task_runner\",\n            connection=self.nc,\n        )\n        await self.assignments_queue.connect()\n        # TODO write only:\n        self.completions_queue = NATSQueue(\n            connection=self.nc, stream=\"jobs\", subject=\"jobs.task_completions\"\n        )\n        await self.completions_queue.connect()\n\n    async def _run_task(self, task_json: str) -&gt; bool:\n        \"\"\"Validate task assignment data, delegate execution to TaskDispatcher, and notify listeners on completion via the messaging bus.\"\"\"\n        try:\n            assignment = TaskAssignment.model_validate_json(task_json)\n        except ValidationError as e:\n            logger.error(f\"Worker #{self.id}: Skipping invalid task `{task_json}`: {e}\")\n            return\n\n        logger.info(f\"Worker #{self.id}: Starting task {assignment.name}\")\n        task = await self.task_dispatcher.execute(assignment=assignment)\n\n        # Queue task completed message\n        logger.debug(f\"Queueing completed message {task.name}\")\n        await self.completions_queue.enqueue(assignment.model_dump_json())\n\n        # return True =&gt; mark task as completed\n        # TODO handle failures\n        return True\n</code></pre>"},{"location":"reference/worker/#germinate_ai.worker.worker.Worker.connect","title":"<code>connect()</code>  <code>async</code>","text":"<p>Connect to task assignments and completions queue so we can get assignments/send task completion notifications via the message bus.</p> Source code in <code>germinate_ai/worker/worker.py</code> <pre><code>async def connect(self):\n    \"\"\"Connect to task assignments and completions queue so we can get assignments/send task completion notifications via the message bus.\"\"\"\n    self.assignments_queue = NATSQueue(\n        stream=\"jobs\",\n        subject=\"jobs.task_assignments\",\n        durable_consumer=\"task_runner\",\n        connection=self.nc,\n    )\n    await self.assignments_queue.connect()\n    # TODO write only:\n    self.completions_queue = NATSQueue(\n        connection=self.nc, stream=\"jobs\", subject=\"jobs.task_completions\"\n    )\n    await self.completions_queue.connect()\n</code></pre>"},{"location":"reference/worker/#germinate_ai.worker.worker.Worker.run","title":"<code>run()</code>  <code>async</code>","text":"<p>Connect to messaging bus, wait for assignments, and execute them.</p> Source code in <code>germinate_ai/worker/worker.py</code> <pre><code>async def run(self):\n    \"\"\"Connect to messaging bus, wait for assignments, and execute them.\"\"\"\n    next_tick = get_next_tick(self.tick_interval)\n\n    await self.connect()\n    logger.success(f\"Worker #{self.id}: connected to cluster! Waiting for tasks...\")\n\n    while True:\n        last_tick = time.time()\n\n        try:\n            msg = await self.assignments_queue.dequeue()\n            task_json = msg.data\n            # acknowledge message so we don't see it again\n            await msg.ack()\n            success = await self._run_task(task_json)\n            if not success:\n                logger.exception(\"Task execution failure\", task_json)\n        except TimeoutError:\n            pass\n        except asyncio.CancelledError:\n            logger.debug(f\"Worker #{self.id}: Cancelled! Shutting down worker...\")\n            break\n        except Exception as e:\n            logger.exception(\"Error while reading from NATS queue: \", e)\n\n        await asyncio.sleep(next_tick(last_tick=last_tick))\n</code></pre>"},{"location":"reference/worker/#germinate_ai.worker.task_dispatcher.TaskDispatcher","title":"<code>TaskDispatcher</code>","text":"<p>Dispatches tasks to appropriate executors, and updates task state accordingly.</p> <p>Given an enqueued task data, TaskDispatcher gets the correct executor from TaskRegistry and uses it to run the corresponding Task.</p> <p>TaskDispatcher also validates input and output schemas for the task, and updates the task's state before (\"queued\"), and after (\"completed\"/\"failed\") execution.</p> Source code in <code>germinate_ai/worker/task_dispatcher.py</code> <pre><code>class TaskDispatcher:\n    \"\"\"\n    Dispatches tasks to appropriate executors, and updates task state accordingly.\n\n    Given an enqueued task data, TaskDispatcher gets the correct executor from TaskRegistry and uses it to run the corresponding Task.\n\n    TaskDispatcher also validates input and output schemas for the task, and updates the task's state before (\"queued\"),\n    and after (\"completed\"/\"failed\") execution.\n    \"\"\"\n\n    def __init__(self, nc: nats.NatsConnection, sessionmaker: typ.Callable):\n        self.nc = nc\n        self.sessionmaker = sessionmaker\n\n    async def execute(self, assignment: TaskAssignment) -&gt; TaskInstance:\n        \"\"\"Execute the enqueued task.\n\n        Args:\n            assignment (TaskAssignment): Task assignment data\n\n        Returns:\n            TaskInstance: SQLAlchemy model representing persisted task state\n        \"\"\"\n        with self.sessionmaker() as db:\n            # Get corresponding task from DB\n            task = get_task_instance_from_assignment(db, assignment)\n            if task is None:\n                logger.error(f\"No such task: skipping `{assignment}`\")\n                return None\n\n            # Get executor for the task\n            executor = TaskRegistry.get_executor(task.task_executor_name)\n\n            # Get task inputs from dependencies' outputs\n            task_input = await self._get_task_inputs(task)\n\n            # Validate task input\n            task_input = executor.input_schema.model_validate(task_input)\n\n            # Update task's input\n            task.input = task_input.model_dump()\n\n            # Update task's state\n            task.state = TaskStateEnum.queued\n            db.add(task)\n            db.commit()\n\n            # TODO Run task executor pre-exec hook, if any\n\n            # Run the task with executor\n            # TODO handle failures\n            # TODO async tasks\n            logger.debug(\n                f\"Executing task {task.name} with executor {task.task_executor_name}...\"\n            )\n            if executor.is_async():\n                output = await executor(task_input)\n            else:\n                output = executor(task_input)\n\n            # Validate task output\n            task_output = executor.output_schema.model_validate(output)\n            task.output = task_output.model_dump()\n\n            # TODO Run task executor post-exec hook, if any\n\n            # Save task state\n            logger.debug(f\"Completed task {task.name}!\")\n            task.state = TaskStateEnum.completed\n            db.add(task)\n            db.commit()\n\n            # Write output to message bus for children tasks\n            await self._put_task_output(task)\n\n            return task\n\n    async def _get_task_inputs(self, task: TaskInstance) -&gt; dict:\n        \"\"\"Get Task inputs (i.e. outputs from parent tasks) from message bus.\"\"\"\n\n        # TODO nats interface refactor -- not clean here\n        logger.debug(\n            f\"Getting task {task.name}'s dependencies' outputs: `{task.depends_on}`\"\n        )\n\n        task_inputs = []\n        for dep in task.depends_on:\n            input_queue = NATSQueue(\n                connection=self.nc,\n                stream=\"jobs\",\n                subject=f\"jobs.{task.state_instance_id}.from_{dep}.to_descendant\",\n            )\n            await input_queue.connect()\n            msg = await input_queue.dequeue()\n            message = Message.model_validate_json(msg.data)\n            task_inputs.append(message.payload)\n            await msg.ack()\n\n        # Merge all dicts\n        input = dict(ChainMap(*task_inputs))\n\n        return input\n\n    async def _put_task_output(self, task: TaskInstance):\n        \"\"\"Write Task output into message bus for input to any children Tasks.\"\"\"\n\n        logger.debug(f\"Writing task {task.name}'s output\")\n\n        # TODO refactor\n        output_queue = NATSQueue(\n            connection=self.nc,\n            stream=\"jobs\",\n            subject=f\"jobs.{task.state_instance_id}.from_{task.name}.to_descendant\",\n        )\n        await output_queue.connect()\n\n        msg = Message(source=task.name, payload=task.output)\n        await output_queue.enqueue(msg.model_dump_json())\n</code></pre>"},{"location":"reference/worker/#germinate_ai.worker.task_dispatcher.TaskDispatcher.execute","title":"<code>execute(assignment)</code>  <code>async</code>","text":"<p>Execute the enqueued task.</p> <p>Parameters:</p> Name Type Description Default <code>assignment</code> <code>TaskAssignment</code> <p>Task assignment data</p> required <p>Returns:</p> Name Type Description <code>TaskInstance</code> <code>TaskInstance</code> <p>SQLAlchemy model representing persisted task state</p> Source code in <code>germinate_ai/worker/task_dispatcher.py</code> <pre><code>async def execute(self, assignment: TaskAssignment) -&gt; TaskInstance:\n    \"\"\"Execute the enqueued task.\n\n    Args:\n        assignment (TaskAssignment): Task assignment data\n\n    Returns:\n        TaskInstance: SQLAlchemy model representing persisted task state\n    \"\"\"\n    with self.sessionmaker() as db:\n        # Get corresponding task from DB\n        task = get_task_instance_from_assignment(db, assignment)\n        if task is None:\n            logger.error(f\"No such task: skipping `{assignment}`\")\n            return None\n\n        # Get executor for the task\n        executor = TaskRegistry.get_executor(task.task_executor_name)\n\n        # Get task inputs from dependencies' outputs\n        task_input = await self._get_task_inputs(task)\n\n        # Validate task input\n        task_input = executor.input_schema.model_validate(task_input)\n\n        # Update task's input\n        task.input = task_input.model_dump()\n\n        # Update task's state\n        task.state = TaskStateEnum.queued\n        db.add(task)\n        db.commit()\n\n        # TODO Run task executor pre-exec hook, if any\n\n        # Run the task with executor\n        # TODO handle failures\n        # TODO async tasks\n        logger.debug(\n            f\"Executing task {task.name} with executor {task.task_executor_name}...\"\n        )\n        if executor.is_async():\n            output = await executor(task_input)\n        else:\n            output = executor(task_input)\n\n        # Validate task output\n        task_output = executor.output_schema.model_validate(output)\n        task.output = task_output.model_dump()\n\n        # TODO Run task executor post-exec hook, if any\n\n        # Save task state\n        logger.debug(f\"Completed task {task.name}!\")\n        task.state = TaskStateEnum.completed\n        db.add(task)\n        db.commit()\n\n        # Write output to message bus for children tasks\n        await self._put_task_output(task)\n\n        return task\n</code></pre>"},{"location":"reference/core/loader/","title":"Loader","text":""},{"location":"reference/core/loader/#germinate_ai.core.loader.get_workflow_from_module","title":"<code>get_workflow_from_module(module, var_name=None)</code>","text":"<p>Get workflow from the module.</p> <p>Get the workflow stored in <code>var_name</code>, or the first workflow defined from the module.</p> Source code in <code>germinate_ai/core/loader.py</code> <pre><code>def get_workflow_from_module(module: ModuleType, var_name: str = None) -&gt; Workflow:\n    \"\"\"Get workflow from the module.\n\n    Get the workflow stored in `var_name`, or the first workflow defined from the module.\n    \"\"\"\n    workflow = None\n    if var_name:\n        # get workflow with matching variable name\n        workflow = _get_workflow_with_name(module.__dict__, var_name)\n    else:\n        # first Workflow instance found\n        workflow = _get_first_workflow(module.__dict__)\n\n    if workflow is not None:\n        return workflow\n\n    raise WorkflowImportException(\"Could not find any workflows\")\n</code></pre>"},{"location":"reference/core/loader/#germinate_ai.core.loader.import_workflow","title":"<code>import_workflow(workflow_import_path, *, working_dir=None)</code>","text":"<p>Import a workflow instance from the given module.</p> Example usage Source code in <code>germinate_ai/core/loader.py</code> <pre><code>def import_workflow(\n    workflow_import_path: str,\n    *,\n    working_dir: typ.Optional[str] = None,\n):\n    \"\"\"\n    Import a workflow instance from the given module.\n\n    Example usage:\n        # ./simple_metagpt.py\n        import_workflow(\"simple_metagpt:workflow\")\n        import_workflow(\"simple_metagpt:workflow_v2\")\n\n        # ./my_project/workflows/simple_metagpt.py\n        import_workflow(\"workflows.simple_metagpt:workflow\", working_dir=\"./my_project\")\n    \"\"\"\n\n    module_name, var_name = parse_import_path(workflow_import_path)\n    module = import_module(module_name, working_dir=working_dir)\n\n    return get_workflow_from_module(module, var_name=var_name)\n</code></pre>"},{"location":"reference/core/loader/#germinate_ai.core.loader.import_workflow--simple_metagptpy","title":"./simple_metagpt.py","text":"<p>import_workflow(\"simple_metagpt:workflow\") import_workflow(\"simple_metagpt:workflow_v2\")</p>"},{"location":"reference/core/loader/#germinate_ai.core.loader.import_workflow--my_projectworkflowssimple_metagptpy","title":"./my_project/workflows/simple_metagpt.py","text":"<p>import_workflow(\"workflows.simple_metagpt:workflow\", working_dir=\"./my_project\")</p>"},{"location":"reference/core/misc/","title":"Exceptions","text":""},{"location":"reference/core/misc/#germinate_ai.core.exceptions.DatabaseUnavailableException","title":"<code>DatabaseUnavailableException</code>","text":"<p>             Bases: <code>GerminateAIException</code></p> <p>Database backend in not reachable.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class DatabaseUnavailableException(GerminateAIException):\n    \"\"\"Database backend in not reachable.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/misc/#germinate_ai.core.exceptions.GerminateAIException","title":"<code>GerminateAIException</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Base class for Germinate AI exceptions.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class GerminateAIException(Exception):\n    \"\"\"Base class for Germinate AI exceptions.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/misc/#germinate_ai.core.exceptions.InvalidArgumentsException","title":"<code>InvalidArgumentsException</code>","text":"<p>             Bases: <code>GerminateAIException</code></p> <p>Invalid arguments.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class InvalidArgumentsException(GerminateAIException):\n    \"\"\"Invalid arguments.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/misc/#germinate_ai.core.exceptions.InvalidConfigurationException","title":"<code>InvalidConfigurationException</code>","text":"<p>             Bases: <code>GerminateAIException</code></p> <p>The configuration is invalid.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class InvalidConfigurationException(GerminateAIException):\n    \"\"\"The configuration is invalid.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/misc/#germinate_ai.core.exceptions.InvalidTasksDagException","title":"<code>InvalidTasksDagException</code>","text":"<p>             Bases: <code>GerminateAIException</code></p> <p>Tasks DAG is invalid.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class InvalidTasksDagException(GerminateAIException):\n    \"\"\"Tasks DAG is invalid.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/misc/#germinate_ai.core.exceptions.InvalidWorkflowException","title":"<code>InvalidWorkflowException</code>","text":"<p>             Bases: <code>GerminateAIException</code></p> <p>Workflow is invalid.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class InvalidWorkflowException(GerminateAIException):\n    \"\"\"Workflow is invalid.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/misc/#germinate_ai.core.exceptions.MessageBusUnavailableException","title":"<code>MessageBusUnavailableException</code>","text":"<p>             Bases: <code>GerminateAIException</code></p> <p>Messaging bus backend in not reachable.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class MessageBusUnavailableException(GerminateAIException):\n    \"\"\"Messaging bus backend in not reachable.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/misc/#germinate_ai.core.exceptions.WorkflowFileNotFoundException","title":"<code>WorkflowFileNotFoundException</code>","text":"<p>             Bases: <code>GerminateAIException</code></p> <p>Could not find the specified workflow definition module file.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class WorkflowFileNotFoundException(GerminateAIException):\n    \"\"\"Could not find the specified workflow definition module file.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/misc/#germinate_ai.core.exceptions.WorkflowImportException","title":"<code>WorkflowImportException</code>","text":"<p>             Bases: <code>GerminateAIException</code></p> <p>Failed to import the specified workflow definition.</p> Source code in <code>germinate_ai/core/exceptions.py</code> <pre><code>class WorkflowImportException(GerminateAIException):\n    \"\"\"Failed to import the specified workflow definition.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/core/states/","title":"States","text":""},{"location":"reference/core/states/#states","title":"States","text":"<p><code>State</code>s are state components of the<code>Workflow</code> state machines and are themselves containers of tasks DAG.</p>"},{"location":"reference/core/states/#germinate_ai.core.states.states.State","title":"<code>State</code>","text":"<p>User defined State in the workflow state machine.</p> Source code in <code>germinate_ai/core/states/states.py</code> <pre><code>@attr.define(init=False, repr=False)\nclass State:\n    \"\"\"\n    User defined State in the workflow state machine.\n    \"\"\"\n\n    name: str\n    _tasks: typ.Sequence[\"TaskDefinition\"]\n    _tasks_dict: dict[str, \"TaskDefinition\"]\n    _conditions: typ.Sequence[\"Condition\"]\n    _dag: typ.Any\n    _phases: typ.Sequence[typ.Sequence[\"TaskDefinition\"]]\n\n    def __init__(self, name: str):\n        self.name = name\n\n        self._tasks = []\n        self._tasks_dict = dict()\n        self._conditions = []\n        self._dag = None\n        self._phases = []\n\n    # Return a task executor/task def type\n    def task(self, namespace: str = \"agent\") -&gt; typ.Callable:\n        \"\"\"Decorator that adds a task to the state's task DAG.\"\"\"\n        decorate = task_decorator_factory(namespace=namespace, state=self)\n        return decorate\n\n    def add_task(self, task: \"TaskDefinition\"):\n        self._tasks.append(task)\n        self._tasks_dict[task.name] = task\n\n    def condition(self) -&gt; typ.Callable:\n        \"\"\"Decorator that adds a condition to the state so that it can be used to define state transitions from it to other states.\"\"\"\n        decorate = condition_decorator_factory(state=self)\n        return decorate\n\n    def add_condition(self, condition: \"Condition\"):\n        self._conditions.append(condition)\n\n    @property\n    def tasks(self) -&gt; typ.Sequence[\"TaskDefinition\"]:\n        return self._tasks\n\n    # TODO\n    def tree(self):\n        \"\"\"Print tasks DAG.\"\"\"\n        pass\n\n    def __and__(self, other: \"Condition\") -&gt; \"Transition\":\n        \"\"\"Supports `State &amp; Condition &gt;&gt; State` internal DSL by returning a new transition corresponding to `State &amp; Condition`.\"\"\"\n        valid = isinstance(other, Condition)\n        if not valid:\n            raise TypeError(\"Protocol only supports `State &amp; Condition`\")\n        transition = Transition(source=self, condition=other)\n        return transition\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;State: {self.name}&gt;\"\n\n    @property\n    def dag(self) -&gt; typ.Any:\n        if self._dag is None:\n            self._dag = build_tasks_dag(self._tasks)\n        return self._dag\n\n    def validate(self) -&gt; bool:\n        \"\"\"Validate that the tasks DAG is acyclic.\"\"\"\n        valid = is_dag(self.dag)\n        if not valid:\n            raise InvalidTasksDagException(\"Invalid Tasks DAG\")\n\n\n    def sorted_tasks_dag(self) -&gt; typ.Sequence[typ.Sequence[str]]:\n        \"\"\"Topologically sort tasks DAG and return task names for each phase.\"\"\"\n        return list(toposort_tasks_phases(self.tasks))\n\n    @property\n    def conditions(self):\n        return self._conditions\n\n    @property\n    def transitions(self):\n        for condition in self._conditions:\n            yield condition.transition\n\n\n    def build(self):\n        \"\"\"Validate tasks DAG, add transition condition evaluation tasks to the DAG, figure out overall input and output schemas.\"\"\"\n        self.validate()\n\n        phases = self.sorted_tasks_dag()\n        # print(phases)\n\n        # If there are multiple tasks at the end\n        # add a task that merges the outputs\n        if len(phases[-1]) &gt; 1:\n            raise NotImplementedError(\"Not implemented: more than one end task in DAG\")\n\n        # keep a ref to a task at the end of the DAG\n        end_task_name = phases[-1][0]\n        end_task = self._tasks_dict[end_task_name]\n\n        # Add transition condition evaluation tasks to \n        # the DAG at the end\n        for condition in self._conditions:\n            transition = condition.transition\n            if transition is not None and transition.is_valid():\n                # print(f\"Adding transition from {self} to {transition.target} on {condition}\")\n                # Order condition task as depending on end task\n                end_task &gt;&gt; condition.task\n                self.add_task(condition.task)\n\n        phases = self.sorted_tasks_dag()\n        logger.debug(f\"{self.name} DAG phases: {phases}\")\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.states.State.__and__","title":"<code>__and__(other)</code>","text":"<p>Supports <code>State &amp; Condition &gt;&gt; State</code> internal DSL by returning a new transition corresponding to <code>State &amp; Condition</code>.</p> Source code in <code>germinate_ai/core/states/states.py</code> <pre><code>def __and__(self, other: \"Condition\") -&gt; \"Transition\":\n    \"\"\"Supports `State &amp; Condition &gt;&gt; State` internal DSL by returning a new transition corresponding to `State &amp; Condition`.\"\"\"\n    valid = isinstance(other, Condition)\n    if not valid:\n        raise TypeError(\"Protocol only supports `State &amp; Condition`\")\n    transition = Transition(source=self, condition=other)\n    return transition\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.states.State.build","title":"<code>build()</code>","text":"<p>Validate tasks DAG, add transition condition evaluation tasks to the DAG, figure out overall input and output schemas.</p> Source code in <code>germinate_ai/core/states/states.py</code> <pre><code>def build(self):\n    \"\"\"Validate tasks DAG, add transition condition evaluation tasks to the DAG, figure out overall input and output schemas.\"\"\"\n    self.validate()\n\n    phases = self.sorted_tasks_dag()\n    # print(phases)\n\n    # If there are multiple tasks at the end\n    # add a task that merges the outputs\n    if len(phases[-1]) &gt; 1:\n        raise NotImplementedError(\"Not implemented: more than one end task in DAG\")\n\n    # keep a ref to a task at the end of the DAG\n    end_task_name = phases[-1][0]\n    end_task = self._tasks_dict[end_task_name]\n\n    # Add transition condition evaluation tasks to \n    # the DAG at the end\n    for condition in self._conditions:\n        transition = condition.transition\n        if transition is not None and transition.is_valid():\n            # print(f\"Adding transition from {self} to {transition.target} on {condition}\")\n            # Order condition task as depending on end task\n            end_task &gt;&gt; condition.task\n            self.add_task(condition.task)\n\n    phases = self.sorted_tasks_dag()\n    logger.debug(f\"{self.name} DAG phases: {phases}\")\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.states.State.condition","title":"<code>condition()</code>","text":"<p>Decorator that adds a condition to the state so that it can be used to define state transitions from it to other states.</p> Source code in <code>germinate_ai/core/states/states.py</code> <pre><code>def condition(self) -&gt; typ.Callable:\n    \"\"\"Decorator that adds a condition to the state so that it can be used to define state transitions from it to other states.\"\"\"\n    decorate = condition_decorator_factory(state=self)\n    return decorate\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.states.State.sorted_tasks_dag","title":"<code>sorted_tasks_dag()</code>","text":"<p>Topologically sort tasks DAG and return task names for each phase.</p> Source code in <code>germinate_ai/core/states/states.py</code> <pre><code>def sorted_tasks_dag(self) -&gt; typ.Sequence[typ.Sequence[str]]:\n    \"\"\"Topologically sort tasks DAG and return task names for each phase.\"\"\"\n    return list(toposort_tasks_phases(self.tasks))\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.states.State.task","title":"<code>task(namespace='agent')</code>","text":"<p>Decorator that adds a task to the state's task DAG.</p> Source code in <code>germinate_ai/core/states/states.py</code> <pre><code>def task(self, namespace: str = \"agent\") -&gt; typ.Callable:\n    \"\"\"Decorator that adds a task to the state's task DAG.\"\"\"\n    decorate = task_decorator_factory(namespace=namespace, state=self)\n    return decorate\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.states.State.tree","title":"<code>tree()</code>","text":"<p>Print tasks DAG.</p> Source code in <code>germinate_ai/core/states/states.py</code> <pre><code>def tree(self):\n    \"\"\"Print tasks DAG.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.states.State.validate","title":"<code>validate()</code>","text":"<p>Validate that the tasks DAG is acyclic.</p> Source code in <code>germinate_ai/core/states/states.py</code> <pre><code>def validate(self) -&gt; bool:\n    \"\"\"Validate that the tasks DAG is acyclic.\"\"\"\n    valid = is_dag(self.dag)\n    if not valid:\n        raise InvalidTasksDagException(\"Invalid Tasks DAG\")\n</code></pre>"},{"location":"reference/core/states/#conditions","title":"Conditions","text":"<p>Types of <code>Task</code> that evaluate if a state <code>Transition</code> should be triggered.</p>"},{"location":"reference/core/states/#germinate_ai.core.states.conditions.Condition","title":"<code>Condition</code>","text":"<p>Conditions evaluate if a state transition should be triggered.</p> Source code in <code>germinate_ai/core/states/conditions.py</code> <pre><code>@attr.define(init=False, repr=False)\nclass Condition:\n    \"\"\"Conditions evaluate if a state transition should be triggered.\"\"\"\n\n    name: str\n\n    state: \"State\"\n\n    task: \"TaskDefinition\"\n    executor: \"TaskExecutor\"\n\n    transition: typ.Optional[\"Transition\"]\n\n    negated_condition: typ.Optional[\"Condition\"]\n\n    def __init__(\n        self,\n        name: str,\n        state: \"State\" = None,\n        transition: \"Transition\" = None,\n        task: \"TaskDefinition\" = None,\n        executor: \"TaskExecutor\" = None,\n    ) -&gt; None:\n        self.name = name\n        self.state = state\n        self.task = task\n        self.executor = executor\n        self.transition = transition\n\n    def __invert__(self) -&gt; str:\n        \"\"\"Return a copy of this condition with the condition negated.\"\"\"\n        raise NotImplementedError(\"Not implemented yet.\")\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Condition: state={self.state.name}, task={self.task.name}&gt;\"\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.conditions.Condition.__invert__","title":"<code>__invert__()</code>","text":"<p>Return a copy of this condition with the condition negated.</p> Source code in <code>germinate_ai/core/states/conditions.py</code> <pre><code>def __invert__(self) -&gt; str:\n    \"\"\"Return a copy of this condition with the condition negated.\"\"\"\n    raise NotImplementedError(\"Not implemented yet.\")\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.conditions.ConditionOutputSchema","title":"<code>ConditionOutputSchema</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>germinate_ai/core/states/conditions.py</code> <pre><code>class ConditionOutputSchema(BaseModel):\n    condition_evaluation: bool\n    \"\"\"Result of evaluating the condition.\"\"\"\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.conditions.ConditionOutputSchema.condition_evaluation","title":"<code>condition_evaluation: bool</code>  <code>instance-attribute</code>","text":"<p>Result of evaluating the condition.</p>"},{"location":"reference/core/states/#germinate_ai.core.states.conditions.condition_decorator_factory","title":"<code>condition_decorator_factory(state, namespace=None)</code>","text":"<p>Creates a decorator that registers a state transition condition for a given State.</p> Source code in <code>germinate_ai/core/states/conditions.py</code> <pre><code>def condition_decorator_factory(\n    state: \"State\", namespace: str = None\n) -&gt; typ.Callable[[typ.Callable], typ.Callable]:\n    \"\"\"Creates a decorator that registers a state transition condition for a given State.\"\"\"\n    if namespace is None:\n        namespace = \"transition_conditions\"\n\n    def decorate(func: typ.Callable[[typ.Concatenate[...]], bool]):\n        # Re-wrap the wrapped condition function in a function that matches the task executor\n        # function protocol\n        if asyncio.iscoroutinefunction(func):\n            @wraps(func)\n            async def wrapper(*args: typ.Any, **kwargs: typ.Any) -&gt; ConditionOutputSchema:\n                bound = resolve_dependencies(func, *args, **kwargs)\n                result = await func(*bound.args, **bound.kwargs)\n                return ConditionOutputSchema(condition_evaluation=result)\n        else:\n            @wraps(func)\n            def wrapper(*args: typ.Any, **kwargs: typ.Any) -&gt; ConditionOutputSchema:\n                bound = resolve_dependencies(func, *args, **kwargs)\n                result = func(*bound.args, **bound.kwargs)\n                return ConditionOutputSchema(condition_evaluation=result)\n\n        # Compose in an executor callable\n        executor_name = (\n            func.__name__\n            if func.__name__.endswith(\"executor\")\n            else f\"{func.__name__}_executor\"\n        )\n        executor = TaskExecutor(\n            namespace=namespace,\n            name=executor_name,\n            # TODO\n            # input schema for condition is the combined output of the final\n            # phase of a state's tasks\n            # output schema is always the eval schema\n            # input_schema=input_schema,\n            input_schema=ConditionInputSchema,\n            output_schema=ConditionOutputSchema,\n            callable=wrapper,\n        )\n        # Compose executor in a task definition so we can add it to\n        # the end of a state's tasks DAG\n        task = TaskDefinition(\n            name=func.__name__,\n            state=state,\n            executor=executor,\n        )\n        # Compose the whole thing in a Condition\n        condition = Condition(\n            name=func.__name__, state=state, task=task, executor=executor\n        )\n\n        # Add condition (not the corresponding task which is added when building the DAG) to state\n        state.add_condition(condition)\n\n        # Register task executor so we can actually schedule and evaluate the condition on workers\n        TaskRegistry.register(\n            namespace=namespace, name=executor_name, executor=executor\n        )\n        return condition\n\n    return decorate\n</code></pre>"},{"location":"reference/core/states/#transitions","title":"Transitions","text":"<p>Transition from one <code>Workflow</code> <code>State</code> to another if a <code>Condition</code> is fulfilled.</p>"},{"location":"reference/core/states/#germinate_ai.core.states.transitions.Transition","title":"<code>Transition</code>","text":"<p>Represents a transition from a source state to a target state when a condition is fulfilled.</p> Source code in <code>germinate_ai/core/states/transitions.py</code> <pre><code>@attr.define(init=False, repr=False)\nclass Transition:\n    \"\"\"Represents a transition from a source state to a target state when a condition is fulfilled.\"\"\"\n\n    _source: \"State\"\n    _target: \"State\"\n    _condition: Condition\n\n    def __init__(\n        self,\n        source: \"State\" = None,\n        condition: Condition = None,\n        target: \"State\" = None,\n    ) -&gt; None:\n        self._source = source\n        self._condition = condition\n        self._target = target\n        self._condition.transition = self\n\n    @property\n    def source(self) -&gt; \"State\":\n        return self._source\n\n    @property\n    def target(self) -&gt; \"State\":\n        return self._target\n\n    @property\n    def condition(self) -&gt; Condition:\n        return self._condition\n\n    def __rshift__(self, other: \"State\") -&gt; \"Transition\":\n        # TODO\n        from .states import State\n        valid = isinstance(other, State)\n        if not valid:\n            raise TypeError(\"Protocol only supports `Transition &gt;&gt; State`\")\n        self._target = other\n        # TODO register transition and use it\n        return self\n\n    def is_valid(self):\n        \"\"\"Is a valid transaction? I.e. has valid source, target and condition.\"\"\"\n        return (\n            self._source is not None\n            and self._condition is not None\n            and self._target is not None\n        )\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Transition: {self._source.name} -&gt; {self._target.name}&gt;\"\n</code></pre>"},{"location":"reference/core/states/#germinate_ai.core.states.transitions.Transition.is_valid","title":"<code>is_valid()</code>","text":"<p>Is a valid transaction? I.e. has valid source, target and condition.</p> Source code in <code>germinate_ai/core/states/transitions.py</code> <pre><code>def is_valid(self):\n    \"\"\"Is a valid transaction? I.e. has valid source, target and condition.\"\"\"\n    return (\n        self._source is not None\n        and self._condition is not None\n        and self._target is not None\n    )\n</code></pre>"},{"location":"reference/core/tasks/","title":"Tasks","text":""},{"location":"reference/core/tasks/#task-definitions","title":"Task Definitions","text":""},{"location":"reference/core/tasks/#germinate_ai.core.tasks.definition.TaskDefinition","title":"<code>TaskDefinition</code>","text":"<p>Represent's a user's definition of a task.</p> <p>Usually not meant to be instantiated directly.</p> <p>The <code>@&lt;state&gt;.task</code> decorator wraps the user defined task executor function in a <code>TaskDefinition</code> behind the scenes (actually wraps the functions in a <code>TaskExecutor</code> which is composed in a <code>TaskDefinition</code>.)</p> Source code in <code>germinate_ai/core/tasks/definition.py</code> <pre><code>@attr.define(init=False, repr=False)\nclass TaskDefinition:\n    \"\"\"Represent's a user's definition of a task.\n\n    Usually not meant to be instantiated directly.\n\n    The `@&lt;state&gt;.task` decorator wraps the user defined task executor function in a `TaskDefinition` behind the scenes (actually\n    wraps the functions in a `TaskExecutor` which is composed in a `TaskDefinition`.)\n    \"\"\"\n\n    name: str\n    state: typ.Optional[\"State\"]\n\n    # Define one of \n    # - executor (define your own executor), or\n    # - executor_name (use a preset executor)\n    executor: typ.Optional[TaskExecutor]\n    executor_name: typ.Optional[str]\n\n    _parents: set[\"TaskDefinition\"]\n    _children: set[\"TaskDefinition\"]\n\n    def __init__(\n        self,\n        name: str,\n        *,\n        executor: TaskExecutor = None,\n        executor_name: str = None,\n        state: \"State\" = None,\n    ):\n        self.name = name\n        self.state = state\n\n        self.executor = executor\n        self.executor_name = executor_name\n\n        self._parents = set()\n        self._children = set()\n\n    def __call__(self, *args: typ.Any, **kwargs: typ.Any) -&gt; BaseModel:\n        # delegate to executor\n        return self.executor(*args, **kwargs)\n\n    def __hash__(self):\n        return hash(f\"{self.state.name}.{self.name}\")\n\n    @property\n    def parents(self) -&gt; list[str]:\n        return self._parents\n\n    @property\n    def children(self) -&gt; list[str]:\n        return self._children\n\n    def add_parents(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n        \"\"\"This task depends on other tasks.\"\"\"\n        if not isinstance(others, typ.Sequence):\n            others = [others]\n\n        self._parents.update(others)\n        for other in others:\n            other._children.add(self)\n\n    def add_children(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n        \"\"\"Other tasks depend on this task.\"\"\"\n        if not isinstance(others, typ.Sequence):\n            others = [others]\n\n        self._children.update(others)\n        for other in others:\n            other._parents.add(self)\n\n    def __lshift__(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n        \"\"\"\n        Task &lt;&lt; Task | [Task]\n\n        This task depends on other task(s).\n        \"\"\"\n        self.add_parents(others)\n        # Note: Returning right hand side for fluent like DAG definition\n        return others\n\n    def __rshift__(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n        \"\"\"\n        Task &gt;&gt; Task | [Task]\n\n        Other task(s) depend on this task.\n        \"\"\"\n        self.add_children(others)\n        # Note: Returning right hand side for fluent like DAG definition\n        return others\n\n    def __rlshift__(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n        \"\"\"\n        Task | [Task] &lt;&lt; (this) Task\n\n        Other task(s) depend on this task.\n        \"\"\"\n        self.__rshift__(others)\n        return self\n\n    def __rrshift__(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n        \"\"\"\n        Task | [Task] &gt;&gt; (this) task\n\n        This task depends on other task(s).\n        \"\"\"\n        self.__lshift__(others)\n        return self\n\n    def __repr__(self) -&gt; str:\n        state_name = \"\"\n        if self.state:\n            state_name = f\"{self.state.name}.\"\n        prefix = f\"&lt;Task: {state_name}{self.name} \"\n        parents = \", \".join(t.name for t in self.parents)\n        children = \", \".join(t.name for t in self.children)\n        return prefix + f\"(parents: [{parents}], children: [{children}])&gt;\"\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.definition.TaskDefinition.__lshift__","title":"<code>__lshift__(others)</code>","text":"<p>Task &lt;&lt; Task | [Task]</p> <p>This task depends on other task(s).</p> Source code in <code>germinate_ai/core/tasks/definition.py</code> <pre><code>def __lshift__(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n    \"\"\"\n    Task &lt;&lt; Task | [Task]\n\n    This task depends on other task(s).\n    \"\"\"\n    self.add_parents(others)\n    # Note: Returning right hand side for fluent like DAG definition\n    return others\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.definition.TaskDefinition.__rlshift__","title":"<code>__rlshift__(others)</code>","text":"<p>Task | [Task] &lt;&lt; (this) Task</p> <p>Other task(s) depend on this task.</p> Source code in <code>germinate_ai/core/tasks/definition.py</code> <pre><code>def __rlshift__(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n    \"\"\"\n    Task | [Task] &lt;&lt; (this) Task\n\n    Other task(s) depend on this task.\n    \"\"\"\n    self.__rshift__(others)\n    return self\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.definition.TaskDefinition.__rrshift__","title":"<code>__rrshift__(others)</code>","text":"<p>Task | [Task] &gt;&gt; (this) task</p> <p>This task depends on other task(s).</p> Source code in <code>germinate_ai/core/tasks/definition.py</code> <pre><code>def __rrshift__(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n    \"\"\"\n    Task | [Task] &gt;&gt; (this) task\n\n    This task depends on other task(s).\n    \"\"\"\n    self.__lshift__(others)\n    return self\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.definition.TaskDefinition.__rshift__","title":"<code>__rshift__(others)</code>","text":"<p>Task &gt;&gt; Task | [Task]</p> <p>Other task(s) depend on this task.</p> Source code in <code>germinate_ai/core/tasks/definition.py</code> <pre><code>def __rshift__(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n    \"\"\"\n    Task &gt;&gt; Task | [Task]\n\n    Other task(s) depend on this task.\n    \"\"\"\n    self.add_children(others)\n    # Note: Returning right hand side for fluent like DAG definition\n    return others\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.definition.TaskDefinition.add_children","title":"<code>add_children(others)</code>","text":"<p>Other tasks depend on this task.</p> Source code in <code>germinate_ai/core/tasks/definition.py</code> <pre><code>def add_children(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n    \"\"\"Other tasks depend on this task.\"\"\"\n    if not isinstance(others, typ.Sequence):\n        others = [others]\n\n    self._children.update(others)\n    for other in others:\n        other._parents.add(self)\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.definition.TaskDefinition.add_parents","title":"<code>add_parents(others)</code>","text":"<p>This task depends on other tasks.</p> Source code in <code>germinate_ai/core/tasks/definition.py</code> <pre><code>def add_parents(self, others: \"TaskDefinition\" | typ.Sequence[\"TaskDefinition\"]):\n    \"\"\"This task depends on other tasks.\"\"\"\n    if not isinstance(others, typ.Sequence):\n        others = [others]\n\n    self._parents.update(others)\n    for other in others:\n        other._children.add(self)\n</code></pre>"},{"location":"reference/core/tasks/#task-executors","title":"Task Executors","text":""},{"location":"reference/core/tasks/#germinate_ai.core.tasks.executors.BaseTaskExecutor","title":"<code>BaseTaskExecutor</code>","text":"<p>             Bases: <code>Callable[Concatenate[...], Any]</code></p> <p>Base class for task executors.</p> Source code in <code>germinate_ai/core/tasks/executors/base.py</code> <pre><code>class BaseTaskExecutor(Callable[typ.Concatenate[...], typ.Any]):\n    \"\"\"Base class for task executors.\"\"\"\n\n    # The name used to find this executor from the registry\n    name: str\n\n    @abstractmethod\n    def __call__(self, *args: typ.Any, **kwargs: typ.Any) -&gt; typ.Any:\n        pass\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.executors.TaskExecutor","title":"<code>TaskExecutor</code>","text":"<p>             Bases: <code>BaseTaskExecutor</code></p> <p><code>TaskExecutor</code>s execute tasks on workers.</p> <p>Task definitions, using a namespace and the executor name, specify the executor that workers should use to execute specific tasks.</p> Source code in <code>germinate_ai/core/tasks/executors/task_executor.py</code> <pre><code>@attr.define(init=False, repr=False)\nclass TaskExecutor(BaseTaskExecutor):\n    \"\"\"`TaskExecutor`s execute tasks on workers.\n\n    Task definitions, using a namespace and the executor name, specify the executor that workers should use to execute specific tasks.\n    \"\"\"\n\n    namespace: str\n    name: str\n\n    input_schema: BaseModel\n    output_schema: BaseModel\n\n    callable: TaskExecutorCallable\n    _callable_sig: inspect.Signature\n\n    def __init__(\n        self,\n        name: str,\n        callable: TaskExecutorCallable,\n        *,\n        input_schema: BaseModel = None,\n        output_schema: BaseModel = None,\n        namespace: str = \"custom_tasks\",\n    ):\n        self.namespace = namespace\n        self.name = name\n        self.input_schema = input_schema\n        self.output_schema = output_schema\n\n        self.callable = callable\n        self._callable_sig = None\n\n    def __call__(self, *args: typ.Any, **kwargs: typ.Any) -&gt; BaseModel:\n        return self.callable(*args, **kwargs)\n\n    def __hash__(self):\n        return hash(f\"{self.namepace}.{self.name}\")\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Task Executor: {self.name} &gt;\"\n\n    def is_async(self) -&gt; bool:\n        \"\"\"Is the underlying callable a coroutine function?\"\"\"\n        return asyncio.iscoroutinefunction(self.callable)\n\n    @property\n    def registered_name(self) -&gt; str:\n        \"\"\"Name the task executor is registered under.\"\"\"\n        return f\"{self.namespace}.{self.name}\"\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.executors.TaskExecutor.registered_name","title":"<code>registered_name: str</code>  <code>property</code>","text":"<p>Name the task executor is registered under.</p>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.executors.TaskExecutor.is_async","title":"<code>is_async()</code>","text":"<p>Is the underlying callable a coroutine function?</p> Source code in <code>germinate_ai/core/tasks/executors/task_executor.py</code> <pre><code>def is_async(self) -&gt; bool:\n    \"\"\"Is the underlying callable a coroutine function?\"\"\"\n    return asyncio.iscoroutinefunction(self.callable)\n</code></pre>"},{"location":"reference/core/tasks/#task-registry","title":"Task Registry","text":"<p>Registry for task executors.</p>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.registry.TaskKey","title":"<code>TaskKey</code>","text":"<p>Key used to find a task in the registry by namespace and task name.</p> Source code in <code>germinate_ai/core/tasks/registry.py</code> <pre><code>@attr.define(frozen=True, slots=True)\nclass TaskKey:\n    \"\"\"Key used to find a task in the registry by namespace and task name.\"\"\"\n\n    namespace: str\n    name: str\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.registry.TaskRegistry","title":"<code>TaskRegistry</code>","text":"<p>Registry of registered task definitions.</p> Source code in <code>germinate_ai/core/tasks/registry.py</code> <pre><code>class TaskRegistry:\n    \"\"\"Registry of registered task definitions.\"\"\"\n\n    _namespaces: set[str] = set()\n    _tasks: dict[TaskKey, TaskExecutor] = {}\n\n    @classmethod\n    def register(cls, namespace: str, name: str, executor: TaskExecutor):\n        \"\"\"Register a task executor.\"\"\"\n        cls._namespaces.add(namespace)\n        k = TaskKey(namespace=namespace, name=name)\n        # TODO check if overwrites\n        cls._tasks[k] = executor\n\n    @classmethod\n    def get_executor(cls, executor_name: str) -&gt; TaskExecutor:\n        namespace, name = executor_name.split(sep=\".\", maxsplit=1)\n        return cls.get(namespace=namespace, name=name)\n\n    @classmethod\n    def get(cls, namespace: str, name: str) -&gt; TaskExecutor:\n        \"\"\"Get a registered task executor.\"\"\"\n        if namespace not in cls._namespaces:\n            raise KeyError(f\"No such namespace {namespace}\")\n        k = TaskKey(namespace=namespace, name=name)\n        if k not in cls._tasks:\n            raise KeyError(f\"No task executor registered for {name}\")\n        return cls._tasks[k]\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.registry.TaskRegistry.get","title":"<code>get(namespace, name)</code>  <code>classmethod</code>","text":"<p>Get a registered task executor.</p> Source code in <code>germinate_ai/core/tasks/registry.py</code> <pre><code>@classmethod\ndef get(cls, namespace: str, name: str) -&gt; TaskExecutor:\n    \"\"\"Get a registered task executor.\"\"\"\n    if namespace not in cls._namespaces:\n        raise KeyError(f\"No such namespace {namespace}\")\n    k = TaskKey(namespace=namespace, name=name)\n    if k not in cls._tasks:\n        raise KeyError(f\"No task executor registered for {name}\")\n    return cls._tasks[k]\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.registry.TaskRegistry.register","title":"<code>register(namespace, name, executor)</code>  <code>classmethod</code>","text":"<p>Register a task executor.</p> Source code in <code>germinate_ai/core/tasks/registry.py</code> <pre><code>@classmethod\ndef register(cls, namespace: str, name: str, executor: TaskExecutor):\n    \"\"\"Register a task executor.\"\"\"\n    cls._namespaces.add(namespace)\n    k = TaskKey(namespace=namespace, name=name)\n    # TODO check if overwrites\n    cls._tasks[k] = executor\n</code></pre>"},{"location":"reference/core/tasks/#decorators","title":"Decorators","text":"<p>Decorators to convert functions into task definitions.</p>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.decorators.task_decorator_factory","title":"<code>task_decorator_factory(namespace, state)</code>","text":"<p>Creates a decorator that registers a task execution in the given namespace.</p> Source code in <code>germinate_ai/core/tasks/decorators.py</code> <pre><code>def task_decorator_factory(\n    namespace: str, state: \"State\"\n) -&gt; typ.Callable[[typ.Callable], typ.Callable]:\n    \"\"\"Creates a decorator that registers a task execution in the given namespace.\"\"\"\n\n    def decorate(func: typ.Callable):\n        # Get IO Schemas\n        input_schema, output_schema = get_io_schemas(func)\n\n        # Resolve DI arguments\n        wrapper = resolve_dependencies_wrapper(func)\n\n        # Wrap in an executor callable\n        executor_name = (\n            func.__name__\n            if func.__name__.endswith(\"executor\")\n            else f\"{func.__name__}_executor\"\n        )\n        executor = TaskExecutor(\n            namespace=namespace,\n            name=executor_name,\n            input_schema=input_schema,\n            output_schema=output_schema,\n            callable=wrapper,\n        )\n\n        # Wrap executor in a task definition\n        task = TaskDefinition(\n            name=func.__name__,\n            state=state,\n            executor=executor,\n        )\n\n        # Add to state\n        state.add_task(task)\n\n        # Register task executor\n        TaskRegistry.register(\n            namespace=namespace, name=executor_name, executor=executor\n        )\n        return task\n\n    return decorate\n</code></pre>"},{"location":"reference/core/tasks/#algorithms","title":"Algorithms","text":"<p>Topological sorting tasks DAG using <code>networkx</code>.</p>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.algorithms.build_tasks_dag","title":"<code>build_tasks_dag(tasks)</code>","text":"<p>Build NetworkX Directed Graph from a list of tasks.</p> Source code in <code>germinate_ai/core/tasks/algorithms.py</code> <pre><code>def build_tasks_dag(tasks: typ.Sequence[TaskDefinition]) -&gt; nx.DiGraph:\n    \"\"\"Build NetworkX Directed Graph from a list of tasks.\"\"\"\n    g = nx.DiGraph()\n    for task in tasks:\n        g.add_node(task.name, task=task)\n        for dep in task.parents:\n            g.add_edge(dep.name, task.name)\n    return g\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.algorithms.is_dag","title":"<code>is_dag(g)</code>","text":"<p>Check that the graph is a DAG.</p> Source code in <code>germinate_ai/core/tasks/algorithms.py</code> <pre><code>def is_dag(g: nx.DiGraph) -&gt; bool:\n    \"\"\"Check that the graph is a DAG.\"\"\"\n    return nx.is_directed_acyclic_graph(g)\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.algorithms.topological_generations","title":"<code>topological_generations(g)</code>","text":"<p>Get topologically sorted generations from a DAG.</p> Source code in <code>germinate_ai/core/tasks/algorithms.py</code> <pre><code>def topological_generations(g: nx.DiGraph) -&gt; typ.Generator[list[str], None, None]:\n    \"\"\"Get topologically sorted generations from a DAG.\"\"\"\n    if not nx.is_directed_acyclic_graph(g):\n        raise TypeError(\"Invalid tasks specification: not a DAG\")\n\n    return nx.topological_generations(g)\n</code></pre>"},{"location":"reference/core/tasks/#germinate_ai.core.tasks.algorithms.toposort_tasks_phases","title":"<code>toposort_tasks_phases(tasks)</code>","text":"<p>Get \"phases\" of tasks from a list of tasks, so that all the tasks in a single phase can be run in parallel.</p> Source code in <code>germinate_ai/core/tasks/algorithms.py</code> <pre><code>def toposort_tasks_phases(tasks: typ.Sequence[TaskDefinition]) -&gt; typ.Generator[list[str], None, None]:\n    \"\"\"Get \"phases\" of tasks from a list of tasks, so that all the tasks in a single phase can be run in parallel.\"\"\"\n    g = build_tasks_dag(tasks)\n    phases = topological_generations(g)\n    return phases\n</code></pre>"},{"location":"reference/core/workflows/","title":"Workflows","text":""},{"location":"reference/core/workflows/#germinate_ai.core.workflows.Workflow","title":"<code>Workflow</code>","text":"Source code in <code>germinate_ai/core/workflows.py</code> <pre><code>@attr.define(frozen=False, init=False)\nclass Workflow:\n    name: str\n    version: str\n    _states: typ.Sequence[\"State\"]\n    _initial_state: \"State\"\n\n    def __init__(self, name: str, version: str = \"0.1\") -&gt; None:\n        self.name = name\n        self.version = version\n        self._states = []\n        self._initial_state = None\n\n    def add_state(self, state: \"State\", initial_state: bool = False):\n        self._states.append(state)\n        if initial_state:\n            self._initial_state = state\n\n    @property\n    def workflow_id(self):\n        \"\"\"ID used to uniquely identify each version of this workflow.\"\"\"\n        return f\"{self.name}:{self.version}\"\n\n    @property\n    def states(self) -&gt; typ.Sequence[\"State\"]:\n        return self._states\n\n    @property\n    def initial_state(self) -&gt; \"State\":\n        return self._initial_state\n\n    def build(self):\n        \"\"\"Build workflow state machine by building tasks DAG for each state validating transitions between states.\"\"\"\n        for state in self._states:\n            state.build()\n</code></pre>"},{"location":"reference/core/workflows/#germinate_ai.core.workflows.Workflow.workflow_id","title":"<code>workflow_id</code>  <code>property</code>","text":"<p>ID used to uniquely identify each version of this workflow.</p>"},{"location":"reference/core/workflows/#germinate_ai.core.workflows.Workflow.build","title":"<code>build()</code>","text":"<p>Build workflow state machine by building tasks DAG for each state validating transitions between states.</p> Source code in <code>germinate_ai/core/workflows.py</code> <pre><code>def build(self):\n    \"\"\"Build workflow state machine by building tasks DAG for each state validating transitions between states.\"\"\"\n    for state in self._states:\n        state.build()\n</code></pre>"},{"location":"reference/data/database/","title":"Database","text":""},{"location":"reference/data/database/#germinate_ai.data.database.create_db_engine","title":"<code>create_db_engine(db_url=DB_URL)</code>","text":"<p>Create a SQLAlchemy engine.</p> Source code in <code>germinate_ai/data/database.py</code> <pre><code>def create_db_engine(db_url=DB_URL):\n    \"\"\"Create a SQLAlchemy engine.\"\"\"\n    engine = create_engine(db_url)\n    return engine\n</code></pre>"},{"location":"reference/data/database/#germinate_ai.data.database.create_tables","title":"<code>create_tables(engine=None)</code>","text":"<p>Create all defined tables -- DEV ONLY.</p> Source code in <code>germinate_ai/data/database.py</code> <pre><code>def create_tables(engine=None):\n    \"\"\"Create all defined tables -- DEV ONLY.\"\"\"\n    if engine is None:\n        engine = create_db_engine(db_url=DB_URL)\n    logger.info(\"Creating all tables...\")\n    Base.metadata.create_all(bind=engine)\n</code></pre>"},{"location":"reference/data/database/#germinate_ai.data.database.get_db","title":"<code>get_db()</code>","text":"<p>Get a SQLALchemy session.</p> Source code in <code>germinate_ai/data/database.py</code> <pre><code>def get_db():\n    \"\"\"Get a SQLALchemy session.\"\"\"\n    Session = get_db_session()\n    with Session() as db:\n        yield db\n</code></pre>"},{"location":"reference/data/database/#germinate_ai.data.database.get_db_session","title":"<code>get_db_session(engine=None, db_url=DB_URL)</code>","text":"<p>Create a SQLAlchemy session factory.</p> Source code in <code>germinate_ai/data/database.py</code> <pre><code>def get_db_session(engine=None, db_url: str = DB_URL):\n    \"\"\"Create a SQLAlchemy session factory.\"\"\"\n    if engine is None:\n        engine = create_db_engine(db_url)\n    Session = sessionmaker(autoflush=False, bind=engine)\n    return Session\n</code></pre>"},{"location":"reference/data/database/#germinate_ai.data.database.test_db_connection","title":"<code>test_db_connection(db)</code>","text":"<p>Test connection to DB.</p> Source code in <code>germinate_ai/data/database.py</code> <pre><code>def test_db_connection(db: Session) -&gt; Exception | Literal[True]:\n    \"\"\"Test connection to DB.\"\"\"\n    try:\n        db.execute(select(1))\n        return True\n    except Exception as e:\n        return e\n</code></pre>"},{"location":"reference/data/models/","title":"Models","text":""},{"location":"reference/data/models/#workflow-runs","title":"Workflow Runs","text":""},{"location":"reference/data/models/#germinate_ai.data.models.workflow_runs.WorkflowRun","title":"<code>WorkflowRun</code>","text":"<p>             Bases: <code>Base</code></p> <p>One particular run of a workflow.</p> Source code in <code>germinate_ai/data/models/workflow_runs.py</code> <pre><code>class WorkflowRun(Base):\n    \"\"\"One particular run of a workflow.\"\"\"\n    __tablename__ = \"workflow_runs\"\n\n    id: Mapped[UUID] = mapped_column(\n        primary_key=True, server_default=text(\"gen_random_uuid()\")\n    )\n    \"\"\"Workflow run UUID\"\"\"\n\n    workflow_name: Mapped[str] = mapped_column(String())\n\n    workflow_version: Mapped[str] = mapped_column(String())\n\n    workflow_id: Mapped[str] = mapped_column(String())\n\n\n    # picked workflow state_machine\n    workflow_state_machine: Mapped[Workflow] = mapped_column(\n        PickleType(pickler=cloudpickle), nullable=True\n    )\n\n    state: Mapped[WorkflowRunStateEnum] = mapped_column(\n        Enum(WorkflowRunStateEnum), default=WorkflowRunStateEnum.created\n    )\n\n    input: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    output: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    payload: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    attributes: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n\n    state_instances: Mapped[List[\"StateInstance\"]] = relationship(\n        back_populates=\"workflow_run\", foreign_keys=\"StateInstance.workflow_run_id\"\n    )\n\n    # Track name of initial state\n    initial_state_name: Mapped[str] = mapped_column(String())\n\n    current_state_id: Mapped[UUID] = mapped_column(\n        ForeignKey(\"state_instances.id\"), nullable=True\n    )\n    current_state: Mapped[\"StateInstance\"] = relationship(\n        foreign_keys=[current_state_id], post_update=True\n    )\n\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now()\n    )\n    modified_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True),\n        onupdate=func.now(),\n        nullable=True,\n    )\n    completed_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), nullable=True\n    )\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Workflow Run: {self.name}&gt;\"\n\n\n    def state_instance_by_name(self, name: str) -&gt; \"StateInstance\":\n        \"\"\"Find related state instance by name.\"\"\"\n        try:\n            return next(si for si in self.state_instances if si.name == name)\n        except StopIteration:\n            return None\n</code></pre>"},{"location":"reference/data/models/#germinate_ai.data.models.workflow_runs.WorkflowRun.id","title":"<code>id: Mapped[UUID] = mapped_column(primary_key=True, server_default=text('gen_random_uuid()'))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Workflow run UUID</p>"},{"location":"reference/data/models/#germinate_ai.data.models.workflow_runs.WorkflowRun.state_instance_by_name","title":"<code>state_instance_by_name(name)</code>","text":"<p>Find related state instance by name.</p> Source code in <code>germinate_ai/data/models/workflow_runs.py</code> <pre><code>def state_instance_by_name(self, name: str) -&gt; \"StateInstance\":\n    \"\"\"Find related state instance by name.\"\"\"\n    try:\n        return next(si for si in self.state_instances if si.name == name)\n    except StopIteration:\n        return None\n</code></pre>"},{"location":"reference/data/models/#states","title":"States","text":""},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance","title":"<code>StateInstance</code>","text":"<p>             Bases: <code>Base</code></p> <p>An instance of a state in a Workflow State Machine.</p> Source code in <code>germinate_ai/data/models/states.py</code> <pre><code>class StateInstance(Base):\n    \"\"\"An instance of a state in a Workflow State Machine.\"\"\"\n\n    __tablename__ = \"state_instances\"\n\n    id: Mapped[UUID] = mapped_column(\n        primary_key=True, server_default=text(\"gen_random_uuid()\")\n    )\n\n    # State name\n    name: Mapped[str] = mapped_column(String())\n\n    state: Mapped[StateInstanceStateEnum] = mapped_column(\n        Enum(StateInstanceStateEnum), default=StateInstanceStateEnum.created\n    )\n\n    # Store sorted DAG generations i.e. array of (array of tasks that can be run in parallel)\n    sorted_tasks_phases: Mapped[list[list[str]]] = mapped_column(JSON)\n    # index of current running phase\n    current_phase_index: Mapped[int] = mapped_column(default=0)\n\n    transitions: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n\n    input: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    output: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    payload: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    attributes: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n\n    workflow_run_id: Mapped[UUID] = mapped_column(ForeignKey(\"workflow_runs.id\"))\n    workflow_run: Mapped[\"WorkflowRun\"] = relationship(\n        back_populates=\"state_instances\", foreign_keys=[workflow_run_id]\n    )\n\n    task_instances: Mapped[List[\"TaskInstance\"]] = relationship(\n        back_populates=\"state_instance\"\n    )\n\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now()\n    )\n    modified_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), onupdate=func.now(), nullable=True\n    )\n    completed_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), nullable=True\n    )\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;State Instance: {self.name}&gt;\"\n\n    @property\n    def phase_task_names(self):\n        \"\"\"Get the names of all the tasks in the current phase.\"\"\"\n        tasks = set(self.sorted_tasks_phases[self.current_phase_index])\n        return tasks\n\n    @property\n    def current_phase_complete(self):\n        \"\"\"Are all the tasks in the current phase complete?\"\"\"\n        # TODO rewrite this part\n        phase_tasks = self.phase_task_names\n        completed_tasks = {\n            t.name\n            for t in self.task_instances\n            if t.state == TaskInstanceStateEnum.completed\n        }\n        remaining = phase_tasks.difference(completed_tasks)\n        return len(remaining) == 0\n\n    @property\n    def all_phases_complete(self):\n        \"\"\"Are all phases in this state's tasks DAG complete?\"\"\"\n        return (\n            self.current_phase_complete\n            and self.current_phase_index &gt;= len(self.sorted_tasks_phases) - 1\n        )\n\n    @property\n    def phase_tasks(self) -&gt; set[\"TaskInstance\"]:\n        \"\"\"Return a set of tasks in the current phase.\"\"\"\n        tasks= {\n            t for t in self.task_instances\n            if t.name in self.phase_task_names\n        }\n        return tasks\n\n    def next_phase(self) -&gt; typ.Set[\"TaskInstance\"]:\n        \"\"\"Enter next phase by incrementing the phase index and returning all the tasks in the new phase.\n\n        Note: Commit to persist the change.\n        \"\"\"\n        self.current_phase_index += 1\n\n        # sanity check\n        if self.all_phases_complete:\n            self.current_phase_index -= 1\n            raise IndexError(f\"All phases in state {self.name} already complete\")\n\n        return self.phase_tasks\n\n    def final_phase(self) -&gt; typ.Set[\"TaskInstance\"]:\n        \"\"\"Return the \"final\" phase of tasks in the state.\n\n        If a state has transitions, then the actual final phase is composed of transition condition evaluation tasks.\n        In that case, this function instead returns the tasks in the penultimate phase which are actually the last phase of user defined tasks.\n\n        Note: End states, for example, might not have any transitions into other states. \n        \"\"\"\n        # does this state have any transitions\n        has_transitions = len(self.transitions) &gt; 0\n        if has_transitions:\n            final_phase = self.sorted_tasks_phases[-2]\n        else:\n            final_phase = self.sorted_tasks_phases[-1]\n        tasks = {\n            t for t in self.task_instances\n            if t.name in final_phase\n        }\n        return tasks\n\n    def state_output(self) -&gt; dict:\n        \"\"\"Returns the merged output from the final phase of tasks (see `final_phase`).\"\"\"\n        outputs = dict(ChainMap(*(t.output for t in self.final_phase())))\n        return outputs\n\n    def next_state(self) -&gt; str:\n        \"\"\"Figure out the next state to transition to.\"\"\"\n        # Get tasks corresponding to transition tas\n        transition_conditions = {\n            t.name: t for t in self.task_instances\n            if t.name in self.transitions and t.state == TaskInstanceStateEnum.completed\n        }\n\n        # check transition condition evaluations in order\n        # trigger first triggered transition\n        for transition_name, target_state in self.transitions.items():\n            # name -&gt; target state\n            task = transition_conditions[transition_name]\n            output = ConditionOutputSchema.model_validate(task.output)\n            result = output.condition_evaluation\n            if result:\n                return target_state\n\n        return None\n</code></pre>"},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance.all_phases_complete","title":"<code>all_phases_complete</code>  <code>property</code>","text":"<p>Are all phases in this state's tasks DAG complete?</p>"},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance.current_phase_complete","title":"<code>current_phase_complete</code>  <code>property</code>","text":"<p>Are all the tasks in the current phase complete?</p>"},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance.phase_task_names","title":"<code>phase_task_names</code>  <code>property</code>","text":"<p>Get the names of all the tasks in the current phase.</p>"},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance.phase_tasks","title":"<code>phase_tasks: set[TaskInstance]</code>  <code>property</code>","text":"<p>Return a set of tasks in the current phase.</p>"},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance.final_phase","title":"<code>final_phase()</code>","text":"<p>Return the \"final\" phase of tasks in the state.</p> <p>If a state has transitions, then the actual final phase is composed of transition condition evaluation tasks. In that case, this function instead returns the tasks in the penultimate phase which are actually the last phase of user defined tasks.</p> <p>Note: End states, for example, might not have any transitions into other states.</p> Source code in <code>germinate_ai/data/models/states.py</code> <pre><code>def final_phase(self) -&gt; typ.Set[\"TaskInstance\"]:\n    \"\"\"Return the \"final\" phase of tasks in the state.\n\n    If a state has transitions, then the actual final phase is composed of transition condition evaluation tasks.\n    In that case, this function instead returns the tasks in the penultimate phase which are actually the last phase of user defined tasks.\n\n    Note: End states, for example, might not have any transitions into other states. \n    \"\"\"\n    # does this state have any transitions\n    has_transitions = len(self.transitions) &gt; 0\n    if has_transitions:\n        final_phase = self.sorted_tasks_phases[-2]\n    else:\n        final_phase = self.sorted_tasks_phases[-1]\n    tasks = {\n        t for t in self.task_instances\n        if t.name in final_phase\n    }\n    return tasks\n</code></pre>"},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance.next_phase","title":"<code>next_phase()</code>","text":"<p>Enter next phase by incrementing the phase index and returning all the tasks in the new phase.</p> <p>Note: Commit to persist the change.</p> Source code in <code>germinate_ai/data/models/states.py</code> <pre><code>def next_phase(self) -&gt; typ.Set[\"TaskInstance\"]:\n    \"\"\"Enter next phase by incrementing the phase index and returning all the tasks in the new phase.\n\n    Note: Commit to persist the change.\n    \"\"\"\n    self.current_phase_index += 1\n\n    # sanity check\n    if self.all_phases_complete:\n        self.current_phase_index -= 1\n        raise IndexError(f\"All phases in state {self.name} already complete\")\n\n    return self.phase_tasks\n</code></pre>"},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance.next_state","title":"<code>next_state()</code>","text":"<p>Figure out the next state to transition to.</p> Source code in <code>germinate_ai/data/models/states.py</code> <pre><code>def next_state(self) -&gt; str:\n    \"\"\"Figure out the next state to transition to.\"\"\"\n    # Get tasks corresponding to transition tas\n    transition_conditions = {\n        t.name: t for t in self.task_instances\n        if t.name in self.transitions and t.state == TaskInstanceStateEnum.completed\n    }\n\n    # check transition condition evaluations in order\n    # trigger first triggered transition\n    for transition_name, target_state in self.transitions.items():\n        # name -&gt; target state\n        task = transition_conditions[transition_name]\n        output = ConditionOutputSchema.model_validate(task.output)\n        result = output.condition_evaluation\n        if result:\n            return target_state\n\n    return None\n</code></pre>"},{"location":"reference/data/models/#germinate_ai.data.models.states.StateInstance.state_output","title":"<code>state_output()</code>","text":"<p>Returns the merged output from the final phase of tasks (see <code>final_phase</code>).</p> Source code in <code>germinate_ai/data/models/states.py</code> <pre><code>def state_output(self) -&gt; dict:\n    \"\"\"Returns the merged output from the final phase of tasks (see `final_phase`).\"\"\"\n    outputs = dict(ChainMap(*(t.output for t in self.final_phase())))\n    return outputs\n</code></pre>"},{"location":"reference/data/models/#tasks","title":"Tasks","text":""},{"location":"reference/data/models/#germinate_ai.data.models.tasks.TaskInstance","title":"<code>TaskInstance</code>","text":"<p>             Bases: <code>Base</code></p> <p>An instance of a task.</p> Source code in <code>germinate_ai/data/models/tasks.py</code> <pre><code>class TaskInstance(Base):\n    \"\"\"An instance of a task.\"\"\"\n\n    __tablename__ = \"task_instances\"\n\n    id: Mapped[UUID] = mapped_column(\n        primary_key=True, server_default=text(\"gen_random_uuid()\")\n    )\n\n    name: Mapped[str] = mapped_column(String())\n\n    # Just need the names to build subject and get parent tasks' outputs\n    depends_on: Mapped[List[str]] = mapped_column(ARRAY(String), default=[])\n\n    state: Mapped[TaskInstanceStateEnum] = mapped_column(\n        Enum(TaskInstanceStateEnum), default=TaskInstanceStateEnum.created\n    )\n\n    # Need either a name of a preset, or a picked executor\n    task_executor_name: Mapped[str] = mapped_column(nullable=True)\n    task_executor: Mapped[TaskExecutor] = mapped_column(\n        PickleType(pickler=cloudpickle), nullable=True\n    )\n\n    input: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    output: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    payload: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n    attributes: Mapped[dict[str, Any]] = mapped_column(default={}, server_default=\"{}\")\n\n    state_instance_id: Mapped[UUID] = mapped_column(ForeignKey(\"state_instances.id\"))\n    state_instance: Mapped[\"StateInstance\"] = relationship(\n        back_populates=\"task_instances\"\n    )\n\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=func.now()\n    )\n    modified_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), onupdate=func.now(), nullable=True\n    )\n    completed_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), nullable=True\n    )\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Task Instance: {self.name}&gt;\"\n</code></pre>"},{"location":"reference/data/models/#enums","title":"Enums","text":""},{"location":"reference/data/models/#germinate_ai.data.models.enums.StateInstanceStateEnum","title":"<code>StateInstanceStateEnum</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>State progress state.</p> Source code in <code>germinate_ai/data/models/enums.py</code> <pre><code>class StateInstanceStateEnum(str, enum.Enum):\n    \"\"\"State progress state.\"\"\"\n\n    created = \"Created\"\n    queued = \"Queued\"\n    in_progress = \"InProgress\"\n\n    completed = \"Completed\"\n    failed = \"Failed\"\n    canceled = \"Canceled\"\n</code></pre>"},{"location":"reference/data/models/#germinate_ai.data.models.enums.TaskInstanceStateEnum","title":"<code>TaskInstanceStateEnum</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Task progress state.</p> Source code in <code>germinate_ai/data/models/enums.py</code> <pre><code>class TaskInstanceStateEnum(str, enum.Enum):\n    \"\"\"Task progress state.\"\"\"\n\n    created = \"Created\"\n    queued = \"Queued\"\n    in_progress = \"InProgress\"\n\n    completed = \"Completed\"\n    failed = \"Failed\"\n    canceled = \"Canceled\"\n</code></pre>"},{"location":"reference/data/models/#germinate_ai.data.models.enums.WorkflowRunStateEnum","title":"<code>WorkflowRunStateEnum</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Workflow Run progress state.</p> Source code in <code>germinate_ai/data/models/enums.py</code> <pre><code>class WorkflowRunStateEnum(str, enum.Enum):\n    \"\"\"Workflow Run progress state.\"\"\"\n\n    created = \"Created\"\n    queued = \"Queued\"\n    in_progress = \"InProgress\"\n\n    completed = \"Completed\"\n    failed = \"Failed\"\n    canceled = \"Canceled\"\n</code></pre>"},{"location":"reference/data/repositories/","title":"Repositories","text":""},{"location":"reference/data/repositories/#workflow-runs-repository","title":"Workflow Runs Repository","text":""},{"location":"reference/data/repositories/#germinate_ai.data.repositories.workflow_runs_repository.create_run_from_workflow","title":"<code>create_run_from_workflow(db, workflow)</code>","text":"<p>Create a WorkflowRun model from a Workflow specification.</p> Source code in <code>germinate_ai/data/repositories/workflow_runs_repository.py</code> <pre><code>def create_run_from_workflow(db: Session, workflow: Workflow) -&gt; WorkflowRun:\n    \"\"\"Create a WorkflowRun model from a Workflow specification.\"\"\"\n    workflow_run = WorkflowRun(\n        workflow_name=workflow.name,\n        workflow_version=workflow.version,\n        workflow_id=workflow.workflow_id,\n    )\n    workflow_run.state = WorkflowRunStateEnum.created\n    return workflow_run\n</code></pre>"},{"location":"reference/data/repositories/#germinate_ai.data.repositories.workflow_runs_repository.get_workflow_run","title":"<code>get_workflow_run(db, uuid, join_states=True)</code>","text":"<p>Get WorkflowRun from the DB.</p> Source code in <code>germinate_ai/data/repositories/workflow_runs_repository.py</code> <pre><code>def get_workflow_run(db: Session, uuid: UUID, join_states=True) -&gt; WorkflowRun:\n    \"\"\"Get WorkflowRun from the DB.\"\"\"\n    stmt = select(WorkflowRun).where(WorkflowRun.id == uuid)\n    if join_states:\n        stmt = stmt.join(WorkflowRun.state_instances)\n    return db.scalars(stmt).first()\n</code></pre>"},{"location":"reference/data/repositories/#states-repository","title":"States Repository","text":""},{"location":"reference/data/repositories/#germinate_ai.data.repositories.states_repository.get_state","title":"<code>get_state(db, uuid, join_tasks=True)</code>","text":"<p>Get State from DB.</p> Source code in <code>germinate_ai/data/repositories/states_repository.py</code> <pre><code>def get_state(db: Session, uuid: UUID, join_tasks=True) -&gt; StateInstance:\n    \"\"\"Get State from DB.\"\"\"\n    stmt = select(StateInstance).where(StateInstance.id == uuid)\n    if join_tasks:\n        stmt = stmt.join(StateInstance.task_instances)\n    return db.scalars(stmt).first()\n</code></pre>"},{"location":"reference/data/repositories/#tasks-repository","title":"Tasks Repository","text":""},{"location":"reference/data/repositories/#germinate_ai.data.repositories.tasks_repository.get_task_instance_from_assignment","title":"<code>get_task_instance_from_assignment(db, assignment)</code>","text":"<p>Get Task instance from DB from the given assignment.</p> Source code in <code>germinate_ai/data/repositories/tasks_repository.py</code> <pre><code>def get_task_instance_from_assignment(\n    db: Session, assignment: TaskAssignment\n) -&gt; TaskInstance:\n    \"\"\"Get Task instance from DB from the given assignment.\"\"\"\n    stmt = (\n        select(TaskInstance)\n        .where(TaskInstance.state_instance_id == assignment.state_instance_id)\n        .where(TaskInstance.name == assignment.name)\n    )\n    task = db.scalars(stmt).first()\n    return task\n</code></pre>"},{"location":"reference/data/schemas/","title":"Schemas","text":""}]}